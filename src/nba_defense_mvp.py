"""
NBA Defensive Impact (EDI) - MVP Analysis Script
=================================================
Analyzes 5 defensive dimensions and outputs radar charts.

Usage:
    python src/nba_defense_mvp.py           # Default: 2024-25 season
    python src/nba_defense_mvp.py 2025-26   # Specify season
"""

import sys
import io
import pandas as pd
import numpy as np
import time
from pathlib import Path

import matplotlib.pyplot as plt
from scipy import stats
from nba_api.stats.endpoints import (
    leaguedashptdefend,
    leaguehustlestatsplayer,
    leaguedashplayerstats,
    leagueseasonmatchups,
    leaguedashplayerbiostats,
    commonteamroster,
    commonallplayers,
)
from nba_api.stats.static import teams
from sklearn.linear_model import LinearRegression

# Fix Windows console encoding for Chinese characters
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")

# --- Configuration ---
HISTORY_MODE = False
if len(sys.argv) > 1:
    if sys.argv[1] == "--history":
        HISTORY_MODE = True
        SEASON = "2024-25"
    else:
        SEASON = sys.argv[1]
else:
    SEASON = "2024-25"

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
FIGURES_DIR = BASE_DIR / "figures"
DATA_DIR.mkdir(parents=True, exist_ok=True)
FIGURES_DIR.mkdir(parents=True, exist_ok=True)

TARGET_PLAYERS = [
    "Bam Adebayo",
    "Rudy Gobert",
    "Jrue Holiday",
    "Victor Wembanyama",
    "Trae Young",
]

# MIN_GP Â∞ÜÂú®Êï∞ÊçÆËé∑ÂèñÂêéÂä®ÊÄÅËÆ°ÁÆó (ÂΩìÂâçËµõÂ≠£ÊúÄÂ§ßÊØîËµõÂú∫Ê¨°ÁöÑ‰∏ÄÂçä)
MIN_MIN = 15

# Ë¥ùÂè∂ÊñØÊî∂Áº©Â∏∏Êï∞
BAYES_C = 50  # Êî∂Áº©Âº∫Â∫¶ÔºöÊ†∑Êú¨ÈáèËææÂà∞ C Êó∂ÔºåÊï∞ÊçÆÊùÉÈáç = 50%

# =============================================================================
# ËßíËâ≤Áõ∏ÂÖ≥ÊÄßÁ≥ªÊï∞ (Role Relevance Coefficient)
# Guards: Á∫Ø "G" (‰∏çÂê´ F Êàñ C)
# Frontcourt: Âê´ "F" Êàñ "C" (ÂåÖÊã¨ G-F, F-G, F, F-C, C-F, C)
# =============================================================================
ROLE_CONFIG = {
    "Guards": {
        "D2_EXT_WEIGHT": 0.6,  # Â§ñÁ∫ø (‰∏âÂàÜÈò≤ÂÆà) ÊùÉÈáç
        "D2_INT_WEIGHT": 0.4,  # ÂÜÖÁ∫ø (Êä§Á≠ê) ÊùÉÈáç
        "D5_IMPACT": 0.5,  # ÁØÆÊùøÊùÉÈáçË°∞ÂáèÁ≥ªÊï∞
    },
    "Frontcourt": {
        "D2_EXT_WEIGHT": 0.4,  # Â§ñÁ∫ø (‰∏âÂàÜÈò≤ÂÆà) ÊùÉÈáç
        "D2_INT_WEIGHT": 0.6,  # ÂÜÖÁ∫ø (Êä§Á≠ê) ÊùÉÈáç
        "D5_IMPACT": 1.0,  # ÁØÆÊùøÊùÉÈáçÂÆåÊï¥‰øùÁïô
    },
}


def classify_role(position):
    """
    Ê†πÊçÆ‰ΩçÁΩÆÂàÜÁ±ªÁêÉÂëòËßíËâ≤
    Guards: Á∫Ø G (‰∏çÂê´ F Êàñ C)
    Frontcourt: ÂÖ∂‰ªñÊâÄÊúâ (Âê´ F Êàñ C)
    """
    if pd.isna(position) or position == "":
        return "Frontcourt"  # ÈªòËÆ§ÂâçÂú∫
    pos = str(position).upper()
    # Âè™ÊúâÁ∫Ø G ÊâçÁÆó GuardsÔºåÂÖ∂‰ªñÈÉΩÁÆó Frontcourt
    if "F" in pos or "C" in pos:
        return "Frontcourt"
    if "G" in pos:
        return "Guards"
    return "Frontcourt"  # ÈªòËÆ§ÂâçÂú∫


def get_league_data(endpoint_func, **kwargs):
    """Helper to fetch data with retry logic"""
    try:
        # CommonTeamRoster doesn't accept 'season_type_all_star'
        if (
            "CommonTeamRoster" in endpoint_func.__name__
            or "CommonAllPlayers" in endpoint_func.__name__
        ):
            params = {
                "season": SEASON,
                "timeout": 60,
                **kwargs,
            }
        else:
            params = {
                "season": SEASON,
                "season_type_all_star": "Regular Season",
                "timeout": 60,
                **kwargs,
            }

        resp = endpoint_func(**params)
        df = resp.get_data_frames()[0]
        time.sleep(0.6)  # Reduced from 1.2 to speed up loop
        return df
    except Exception as e:
        print(f"  ERROR fetching {endpoint_func.__name__}: {e}")
        return pd.DataFrame()


def standardize_pt_defend_columns(df, fg_pct_col="D_FG_PCT", fga_col="D_FGA"):
    """
    Fix column names for LeagueDashPtDefend.
    Different categories have different column names for FG% and FGA:
    - Overall: D_FG_PCT, D_FGA
    - Less Than 6Ft: LT_06_PCT, LT_06_FGA (Often just FGA or D_FGA)
    - 3 Pointers: FG3_PCT, FG3A
    """
    if df.empty:
        return df

    # Rename PLAYER_ID
    if "CLOSE_DEF_PERSON_ID" in df.columns:
        df = df.rename(columns={"CLOSE_DEF_PERSON_ID": "PLAYER_ID"})

    # Rename FG% column to standard name
    if fg_pct_col in df.columns and fg_pct_col != "D_FG_PCT":
        df = df.rename(columns={fg_pct_col: "D_FG_PCT"})

    potential_fga_cols = ["D_FGA", "FGA", "FG3A", "FGA_LT_06", "LT_06_FGA"]
    found_col = None
    for col in potential_fga_cols:
        if col in df.columns:
            found_col = col
            break

    if found_col:
        if found_col != fga_col:
            df = df.rename(columns={found_col: fga_col})

    if "D_FGA" in df.columns and fga_col != "D_FGA":
        df = df.rename(columns={"D_FGA": fga_col})

    if "FGA" in df.columns and fga_col != "FGA":
        df = df.rename(columns={"FGA": fga_col})

    if "FG3A" in df.columns and fga_col != "FG3A":
        df = df.rename(columns={"FG3A": fga_col})

    return df


def bayesian_score(raw_pct, n, c=BAYES_C):
    """
    Ë¥ùÂè∂ÊñØÊî∂Áº©ÂÖ¨Âºè
    raw_pct: ÂéüÂßãÁôæÂàÜ‰Ωç (0-1)
    n: Ê†∑Êú¨Èáè
    c: Êî∂Áº©Â∏∏Êï∞
    ËøîÂõû: Êî∂Áº©ÂêéÁöÑÂàÜÊï∞, ÁΩÆ‰ø°Â∫¶ÊùÉÈáç
    """
    score = (n * raw_pct + c * 0.5) / (n + c)
    weight = n / (n + c)
    return score, weight


def analyze_season(target_season):
    print(f"\n=== Analyzing Season: {target_season} ===")

    # =============================================================================
    # STEP 1: FETCH DATA
    # =============================================================================

    print("1. Fetching D1: Shot Suppression (Overall)...")
    d1_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="Overall",
    )
    d1_df = standardize_pt_defend_columns(d1_df, fg_pct_col="D_FG_PCT", fga_col="D_FGA")
    print(f"   -> {len(d1_df)} players")

    print("2. Fetching D2: Shot Profile (Rim - Less Than 6Ft)...")
    d2_rim_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="Less Than 6Ft",
    )
    # FIX: Column is 'LT_06_PCT' not 'D_FG_PCT'
    d2_rim_df = standardize_pt_defend_columns(
        d2_rim_df, fg_pct_col="LT_06_PCT", fga_col="LT_06_FGA"
    )
    print(f"   -> {len(d2_rim_df)} players")

    print("3. Fetching D2: Shot Profile (3PT)...")
    d2_3pt_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="3 Pointers",
    )
    # FIX: Column is 'FG3_PCT' not 'D_FG_PCT'
    d2_3pt_df = standardize_pt_defend_columns(
        d2_3pt_df, fg_pct_col="FG3_PCT", fga_col="FG3A"
    )
    print(f"   -> {len(d2_3pt_df)} players")

    print("4. Fetching D3: Hustle Stats...")
    d3_df = get_league_data(
        leaguehustlestatsplayer.LeagueHustleStatsPlayer,
        season=target_season,
        per_mode_time="PerGame",
    )
    print(f"   -> {len(d3_df)} players")

    print("5. Fetching D4: Player Stats (STL, BLK, PF)...")
    d4_df = get_league_data(
        leaguedashplayerstats.LeagueDashPlayerStats,
        season=target_season,
        per_mode_detailed="PerGame",
    )
    print(f"   -> {len(d4_df)} players")

    print("6. Fetching D5: Advanced Stats (DREB_PCT)...")
    d5_adv_df = get_league_data(
        leaguedashplayerstats.LeagueDashPlayerStats,
        season=target_season,
        per_mode_detailed="PerGame",
        measure_type_detailed_defense="Advanced",
    )
    print(f"   -> {len(d5_adv_df)} players")

    # Fetch LeagueSeasonMatchups for Matchup Difficulty calculation
    print("7. Fetching LeagueSeasonMatchups for Matchup Difficulty...")
    matchup_df = pd.DataFrame()
    try:
        matchup_resp = leagueseasonmatchups.LeagueSeasonMatchups(
            season=target_season,
            season_type_playoffs="Regular Season",
            per_mode_simple="Totals",
            timeout=120,
        )
        matchup_df = matchup_resp.get_data_frames()[0]
        print(f"   -> {len(matchup_df)} matchup records")
        time.sleep(0.6)
    except Exception as e:
        print(f"   WARNING: Could not fetch matchups: {e}")

    # =============================================================================
    # STEP 2: DATA PROCESSING
    # =============================================================================
    print("\nProcessing Data...")

    if d4_df.empty:
        print("CRITICAL ERROR: Failed to fetch base player stats. Exiting.")
        return pd.DataFrame()

    # Base DataFrame with eligible players

    # Âä®ÊÄÅËÆ°ÁÆó MIN_GPÔºöÂΩìÂâçËµõÂ≠£ÊúÄÂ§ßÊØîËµõÂú∫Ê¨°ÁöÑ‰∏ÄÂçä
    MAX_GP = d4_df["GP"].max()
    MIN_GP = MAX_GP // 2
    print(f"\n   ÂΩìÂâçËµõÂ≠£ÊúÄÂ§ßÊØîËµõÂú∫Ê¨°: {MAX_GP}, ÂÖ•Âõ¥Èó®Êßõ: GP >= {MIN_GP}")

    base_df = d4_df[(d4_df["GP"] >= MIN_GP) & (d4_df["MIN"] >= MIN_MIN)].copy()[
        ["PLAYER_ID", "PLAYER_NAME", "GP", "MIN", "PF", "STL", "BLK"]
    ]

    # Fetch Position Data
    print("7. Fetching Player Positions...")
    try:
        # Use commonteamroster iterated over teams as fallback if biostats fails or returns incomplete data
        # But first try biostats as it was in original code (commented out but then imported)

        # Original code used leaguedashplayerbiostats at line 336
        bio_df = get_league_data(
            leaguedashplayerbiostats.LeagueDashPlayerBioStats, season=target_season
        )

        # Original code also had a fallback using commonteamroster
        nba_teams = teams.get_teams()
        all_rosters = []

        print("   Fetching rosters for position data (30 teams)...")
        for t in nba_teams:
            try:
                roster = get_league_data(
                    commonteamroster.CommonTeamRoster,
                    season=target_season,
                    team_id=t["id"],
                )
                if not roster.empty:
                    all_rosters.append(roster[["PLAYER_ID", "POSITION"]])
            except:
                pass

        if all_rosters:
            roster_df = pd.concat(all_rosters)
            # Merge position
            base_df = base_df.merge(roster_df, on="PLAYER_ID", how="left")
            base_df["PLAYER_POSITION"] = base_df["POSITION"]  # Unify column name
        else:
            base_df["PLAYER_POSITION"] = "Unknown"

    except Exception as e:
        print(f"   WARNING: Could not fetch positions: {e}")
        base_df["PLAYER_POSITION"] = "Unknown"

    # Merge DREB_PCT from advanced stats
    if not d5_adv_df.empty and "DREB_PCT" in d5_adv_df.columns:
        adv_cols = d5_adv_df[["PLAYER_ID", "DREB_PCT"]]
        base_df = base_df.merge(adv_cols, on="PLAYER_ID", how="left")
        print("   D5 Advanced data merged: OK")
    else:
        print("   WARNING: DREB_PCT data missing, using fallback")
        base_df["DREB_PCT"] = np.nan

    print(f"   -> {len(base_df)} eligible players (GP>={MIN_GP}, MIN>={MIN_MIN})")

    # =============================================================================
    # D1-D5 ÂàÜÊï∞ËÆ°ÁÆó (Ë¥ùÂè∂ÊñØÊî∂Áº©) + ÊùÉÈáç w_k (Ë¥ùÂè∂ÊñØÁΩÆ‰ø°Â∫¶)
    # =============================================================================

    C = BAYES_C

    # --- D4: Defensive IQ (Èò≤ÂÆàÁêÉÂïÜ) ---
    base_df["Stocks"] = base_df["STL"] + base_df["BLK"]
    base_df["D4_Ratio"] = base_df["Stocks"] / (base_df["PF"] + 1)
    base_df["D4_Raw"] = base_df["D4_Ratio"].rank(pct=True)  # ÂéüÂßãÁôæÂàÜ‰Ωç
    base_df["D4_N"] = base_df["MIN"] * base_df["GP"]  # Ê†∑Êú¨Èáè = ÊÄª‰∏äÂú∫ÂàÜÈíüÊï∞
    d4_result = base_df.apply(lambda r: bayesian_score(r["D4_Raw"], r["D4_N"]), axis=1)
    base_df["D4_Score"] = d4_result.apply(lambda x: x[0])
    base_df["W4"] = d4_result.apply(lambda x: x[1])
    print("   D4 (Defensive IQ): OK")

    # =============================================================================
    # Matchup Difficulty (MD) Calculation
    # =============================================================================
    print("   Calculating Matchup Difficulty (MD)...")
    md_df = pd.DataFrame()

    if not matchup_df.empty:
        # Step 1: Calculate each offensive player's scoring ability
        off_agg = (
            matchup_df.groupby("OFF_PLAYER_ID")
            .agg({"PLAYER_PTS": "sum", "PARTIAL_POSS": "sum"})
            .reset_index()
        )
        off_agg = off_agg[off_agg["PARTIAL_POSS"] >= 50]  # Min 50 possessions
        off_agg["OFF_PTS_PER_100"] = (
            off_agg["PLAYER_PTS"] / off_agg["PARTIAL_POSS"]
        ) * 100
        off_ability = off_agg.set_index("OFF_PLAYER_ID")["OFF_PTS_PER_100"].to_dict()

        # Step 2: Calculate each defender's Matchup Difficulty
        def calc_defender_md(group):
            total_poss = 0
            weighted_sum = 0
            for _, row in group.iterrows():
                off_id = row["OFF_PLAYER_ID"]
                poss = row["PARTIAL_POSS"]
                if off_id in off_ability and poss > 0:
                    weighted_sum += off_ability[off_id] * poss
                    total_poss += poss
            if total_poss >= 50:  # Min 50 possessions defended
                return weighted_sum / total_poss
            return np.nan

        def_groups = matchup_df.groupby("DEF_PLAYER_ID")
        md_values = def_groups.apply(calc_defender_md)
        md_df = pd.DataFrame(
            {"PLAYER_ID": md_values.index, "MATCHUP_DIFFICULTY": md_values.values}
        )
        md_df = md_df.dropna()

        # Calculate MD percentile and Z-score for adjustment
        md_mean = md_df["MATCHUP_DIFFICULTY"].mean()
        md_std = md_df["MATCHUP_DIFFICULTY"].std()
        md_df["MD_Zscore"] = (md_df["MATCHUP_DIFFICULTY"] - md_mean) / md_std
        md_df["MD_Percentile"] = md_df["MATCHUP_DIFFICULTY"].rank(pct=True)

        print(f"   -> MD calculated for {len(md_df)} defenders")
        print(f"   -> League avg MD: {md_mean:.2f}, Std: {md_std:.2f}")
    else:
        print("   WARNING: No matchup data available for MD calculation")
        # Define defaults for missing MD
        md_mean = 24.0

    # Merge MD into base_df
    if not md_df.empty:
        base_df = base_df.merge(
            md_df[["PLAYER_ID", "MATCHUP_DIFFICULTY", "MD_Zscore", "MD_Percentile"]],
            on="PLAYER_ID",
            how="left",
        )
        # Fill missing MD with league average (neutral adjustment)
        base_df["MD_Zscore"] = base_df["MD_Zscore"].fillna(0)
        base_df["MD_Percentile"] = base_df["MD_Percentile"].fillna(0.5)
        base_df["MATCHUP_DIFFICULTY"] = base_df["MATCHUP_DIFFICULTY"].fillna(
            md_mean if not md_df.empty else 24.0
        )
        print("   MD merged into base_df: OK")
    else:
        base_df["MD_Zscore"] = 0
        base_df["MD_Percentile"] = 0.5
        base_df["MATCHUP_DIFFICULTY"] = 24.0  # Default league average
        print("   WARNING: MD data unavailable, using default values")

    # --- D1: Shot Suppression (Value Added + Matchup Difficulty Adjustment) ---
    if not d1_df.empty and "D_FG_PCT" in d1_df.columns and "PLAYER_ID" in d1_df.columns:
        d1_min = d1_df[
            ["PLAYER_ID", "D_FG_PCT", "D_FGA", "PCT_PLUSMINUS", "NORMAL_FG_PCT"]
        ]
        base_df = base_df.merge(d1_min, on="PLAYER_ID", how="left")
        base_df.loc[base_df["D_FGA"] < 5, "D_FG_PCT"] = np.nan
        base_df.loc[base_df["D_FGA"] < 5, "PCT_PLUSMINUS"] = np.nan

        # MD adjustment: subtract expected impact from PLUSMINUS
        # Higher MD (defending better scorers) allows higher PLUSMINUS
        # Each +1 std MD allows +1.5% higher opponent FG%
        MD_K = 0.015  # MD adjustment coefficient (1.5% per std)
        base_df["PCT_PLUSMINUS_ADJ"] = base_df["PCT_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )

        # Use adjusted PCT_PLUSMINUS for ranking
        base_df["D1_Raw"] = 1 - base_df["PCT_PLUSMINUS_ADJ"].rank(pct=True)
        base_df["D1_N"] = base_df["D_FGA"].fillna(0) * base_df["GP"]  # Ê†∑Êú¨Èáè

        d1_result = base_df.apply(
            lambda r: bayesian_score(
                r["D1_Raw"] if pd.notna(r["D1_Raw"]) else 0.5, r["D1_N"]
            ),
            axis=1,
        )
        base_df["D1_Score"] = d1_result.apply(lambda x: x[0])
        base_df["W1"] = d1_result.apply(lambda x: x[1])
        print("   D1 (Suppression - Value Added + MD Adjustment): OK")
    else:
        print("   WARNING: D1 data missing")
        base_df["D1_Score"] = 0.5
        base_df["W1"] = 0.0

    # --- D2: Shot Profile (Rim + 3PT) - Value Added + MD Adjustment ---
    # MD adjustment: subtract expected impact (same logic as D1)
    MD_K = 0.015  # MD adjustment coefficient (1.5% per std)

    # Rim (Êä§Á≠ê) - ‰ΩøÁî® PLUSMINUS + MDË∞ÉÊï¥
    if (
        not d2_rim_df.empty
        and "D_FG_PCT" in d2_rim_df.columns
        and "PLAYER_ID" in d2_rim_df.columns
    ):
        d2_rim = d2_rim_df[["PLAYER_ID", "D_FG_PCT", "LT_06_FGA", "PLUSMINUS"]].rename(
            columns={
                "D_FG_PCT": "Rim_DFG",
                "LT_06_FGA": "Rim_FGA",
                "PLUSMINUS": "Rim_PLUSMINUS",
            }
        )
        base_df = base_df.merge(d2_rim, on="PLAYER_ID", how="left")
        # MD Adjustment for Rim: subtract expected impact
        base_df["Rim_PLUSMINUS_ADJ"] = base_df["Rim_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )
        # Value Added: PLUSMINUS Ë∂äË¥üË∂äÂ•Ω (‰ΩøÁî®Ë∞ÉÊï¥ÂêéÁöÑÂÄº)
        base_df["Rim_Raw"] = 1 - base_df["Rim_PLUSMINUS_ADJ"].rank(pct=True)
        print("   D2 (Rim - Value Added + MD): OK")
    else:
        print(
            "   WARNING: D2 Rim data missing - columns:",
            d2_rim_df.columns.tolist() if not d2_rim_df.empty else "EMPTY",
        )
        base_df["Rim_Raw"] = 0.5
        base_df["Rim_FGA"] = 0
        base_df["Rim_PLUSMINUS"] = np.nan
        base_df["Rim_PLUSMINUS_ADJ"] = np.nan

    # 3PT (‰∏âÂàÜ) - ‰ΩøÁî® PLUSMINUS + MDË∞ÉÊï¥
    if (
        not d2_3pt_df.empty
        and "D_FG_PCT" in d2_3pt_df.columns
        and "PLAYER_ID" in d2_3pt_df.columns
    ):
        d2_3pt = d2_3pt_df[["PLAYER_ID", "D_FG_PCT", "FG3A", "PLUSMINUS"]].rename(
            columns={
                "D_FG_PCT": "3PT_DFG",
                "FG3A": "FG3_FGA",
                "PLUSMINUS": "3PT_PLUSMINUS",
            }
        )
        base_df = base_df.merge(d2_3pt, on="PLAYER_ID", how="left")
        # MD Adjustment for 3PT: subtract expected impact
        base_df["3PT_PLUSMINUS_ADJ"] = base_df["3PT_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )
        # Value Added: PLUSMINUS Ë∂äË¥üË∂äÂ•Ω (‰ΩøÁî®Ë∞ÉÊï¥ÂêéÁöÑÂÄº)
        base_df["3PT_Raw"] = 1 - base_df["3PT_PLUSMINUS_ADJ"].rank(pct=True)
        print("   D2 (3PT - Value Added + MD): OK")
    else:
        print(
            "   WARNING: D2 3PT data missing - columns:",
            d2_3pt_df.columns.tolist() if not d2_3pt_df.empty else "EMPTY",
        )
        base_df["3PT_Raw"] = 0.5
        base_df["FG3_FGA"] = 0
        base_df["3PT_PLUSMINUS"] = np.nan
        base_df["3PT_PLUSMINUS_ADJ"] = np.nan

    # Combined D2: Âü∫‰∫éËßíËâ≤ÁöÑÂÜÖÂ§ñÁ∫øÊùÉÈáç
    rim_raw = base_df["Rim_Raw"].fillna(0.5)
    pt3_raw = base_df["3PT_Raw"].fillna(0.5)

    # Ê∑ªÂä†ËßíËâ≤ÂàÜÁ±ª
    base_df["ROLE"] = base_df["PLAYER_POSITION"].apply(classify_role)

    def calc_d2_raw(row):
        role = row["ROLE"]
        config = ROLE_CONFIG[role]
        return (rim_raw[row.name] * config["D2_INT_WEIGHT"]) + (
            pt3_raw[row.name] * config["D2_EXT_WEIGHT"]
        )

    base_df["D2_Raw"] = base_df.apply(calc_d2_raw, axis=1)

    # Ê†∑Êú¨Èáè = Êä§Á≠êÈò≤ÂÆàÊ¨°Êï∞ + ‰∏âÂàÜÈò≤ÂÆàÊ¨°Êï∞ (Âü∫‰∫éËßíËâ≤Âä†ÊùÉ)
    rim_fga = base_df["Rim_FGA"].fillna(0) * base_df["GP"]
    fg3_fga = base_df["FG3_FGA"].fillna(0) * base_df["GP"]

    def calc_d2_n(row):
        role = row["ROLE"]
        config = ROLE_CONFIG[role]
        return (rim_fga[row.name] * config["D2_INT_WEIGHT"]) + (
            fg3_fga[row.name] * config["D2_EXT_WEIGHT"]
        )

    base_df["D2_N"] = base_df.apply(calc_d2_n, axis=1)

    d2_result = base_df.apply(lambda r: bayesian_score(r["D2_Raw"], r["D2_N"]), axis=1)
    base_df["D2_Score"] = d2_result.apply(lambda x: x[0])
    base_df["W2"] = d2_result.apply(lambda x: x[1])

    # --- D3: Hustle Index ---
    if not d3_df.empty:
        hustle_cols = d3_df[
            ["PLAYER_ID", "DEFLECTIONS", "CHARGES_DRAWN", "CONTESTED_SHOTS"]
        ]
        base_df = base_df.merge(hustle_cols, on="PLAYER_ID", how="left")

        defl = base_df["DEFLECTIONS"].fillna(0)
        chrg = base_df["CHARGES_DRAWN"].fillna(0)
        cont = base_df["CONTESTED_SHOTS"].fillna(0)

        base_df["Z_Defl"] = stats.zscore(defl)
        base_df["Z_Chrg"] = stats.zscore(chrg)
        base_df["Z_Cont"] = stats.zscore(cont)

        base_df["Hustle_Raw"] = (
            base_df["Z_Defl"] + (base_df["Z_Chrg"] * 2) + base_df["Z_Cont"]
        )
        base_df["D3_Raw"] = base_df["Hustle_Raw"].rank(pct=True)
        base_df["D3_N"] = base_df["MIN"] * base_df["GP"]

        d3_result = base_df.apply(
            lambda r: bayesian_score(r["D3_Raw"], r["D3_N"]), axis=1
        )
        base_df["D3_Score"] = d3_result.apply(lambda x: x[0])
        base_df["W3"] = d3_result.apply(lambda x: x[1])
        print("   D3 (Hustle): OK")
    else:
        print("   WARNING: D3 Hustle data missing")
        base_df["D3_Score"] = 0.5
        base_df["W3"] = 0.0

    # --- D5: Anchor / Rebound Protection (ÁØÆÊùø‰øùÊä§) ---
    base_df["D5_Raw"] = base_df["DREB_PCT"].rank(pct=True)
    base_df["D5_N"] = base_df["MIN"] * base_df["GP"]

    d5_result = base_df.apply(
        lambda r: bayesian_score(
            r["D5_Raw"] if pd.notna(r["D5_Raw"]) else 0.5, r["D5_N"]
        ),
        axis=1,
    )
    base_df["D5_Score"] = d5_result.apply(lambda x: x[0])
    base_df["W5_Base"] = d5_result.apply(lambda x: x[1])

    # Â∫îÁî®ËßíËâ≤Áõ∏ÂÖ≥ÊÄßÁ≥ªÊï∞ (Role Relevance Coefficient)
    base_df["W5"] = base_df.apply(
        lambda r: r["W5_Base"] * ROLE_CONFIG[r["ROLE"]]["D5_IMPACT"], axis=1
    )
    print("   D5 (Anchor/DREB%): OK (Role-adjusted)")

    # =============================================================================
    # ÊïàÁéáÊ®°ÂûãÊ°ÜÊû∂ (Efficiency Model Framework)
    # =============================================================================

    # Fill NaN scores with 0.5 (neutral)
    score_cols = ["D1_Score", "D2_Score", "D3_Score", "D4_Score", "D5_Score"]
    weight_cols = ["W1", "W2", "W3", "W4", "W5"]

    for col in score_cols:
        base_df[col] = base_df[col].fillna(0.5)

    for col in weight_cols:
        base_df[col] = base_df[col].fillna(0)

    # Step 1: ËÆ°ÁÆóÂÆûÈôÖ‰∫ßÂá∫ (D1 + D2 ÁöÑÂä†ÊùÉÂπ≥Âùá)
    base_df["Actual_Output"] = (
        base_df["D1_Score"] * base_df["W1"] + base_df["D2_Score"] * base_df["W2"]
    ) / (base_df["W1"] + base_df["W2"] + 1e-6)

    # Step 2: ËÆ°ÁÆóÊäïÂÖ•ÂàÜ (D3 + D4 ÁöÑÂä†ÊùÉÂπ≥Âùá)
    base_df["Input_Score"] = (
        base_df["D3_Score"] * base_df["W3"] + base_df["D4_Score"] * base_df["W4"]
    ) / (base_df["W3"] + base_df["W4"] + 1e-6)

    # Step 3: Áî®Á∫øÊÄßÂõûÂΩíÂª∫Á´ã ÊäïÂÖ• ‚Üí È¢ÑÊúü‰∫ßÂá∫ ÁöÑÊ®°Âûã
    valid_mask = (
        (base_df["W1"] > 0.1)
        & (base_df["W2"] > 0.1)
        & (base_df["W3"] > 0.1)
        & (base_df["W4"] > 0.1)
    )
    if valid_mask.sum() > 10:
        X_train = base_df.loc[valid_mask, "Input_Score"].values.reshape(-1, 1)
        y_train = base_df.loc[valid_mask, "Actual_Output"].values

        reg_model = LinearRegression()
        reg_model.fit(X_train, y_train)

        # È¢ÑÊµãÊâÄÊúâÁêÉÂëòÁöÑÈ¢ÑÊúü‰∫ßÂá∫
        base_df["Expected_Output"] = reg_model.predict(
            base_df["Input_Score"].values.reshape(-1, 1)
        )

        print(
            f"   ÂõûÂΩíÊ®°Âûã: Expected_Output = {reg_model.intercept_:.4f} + {reg_model.coef_[0]:.4f} * Input_Score"
        )
        print(f"   R¬≤ = {reg_model.score(X_train, y_train):.4f}")
    else:
        print(
            "   WARNING: Not enough valid data for regression model. Using Actual as Expected."
        )
        base_df["Expected_Output"] = base_df["Actual_Output"]
        # Dummy model for Hansen logic
        reg_model = LinearRegression()
        reg_model.intercept_ = 0
        reg_model.coef_ = np.array([1.0])

    # Step 4: ËÆ°ÁÆóÊïàÁéáÁ≥ªÊï∞
    base_df["Efficiency"] = base_df["Actual_Output"] / (
        base_df["Expected_Output"] + 1e-6
    )
    base_df["Efficiency"] = base_df["Efficiency"].clip(0.5, 1.5)

    # Step 5: ËÆ°ÁÆóÊñ∞ÁöÑ EDI
    output_weighted = (
        base_df["Actual_Output"]
        * base_df["Efficiency"]
        * (base_df["W1"] + base_df["W2"])
    )
    input_weighted = base_df["Input_Score"] * (base_df["W3"] + base_df["W4"])
    d5_weighted = base_df["D5_Score"] * base_df["W5"]

    total_weight = (
        base_df["W1"] + base_df["W2"] + base_df["W3"] + base_df["W4"] + base_df["W5"]
    )

    base_df["EDI_Total"] = np.where(
        total_weight > 0,
        (output_weighted + input_weighted + d5_weighted) / total_weight * 100,
        50.0,
    )

    # ËÆ°ÁÆóÊïàÁéáÊÆãÂ∑Æ (Áî®‰∫éÂàÜÊûê)
    base_df["Efficiency_Residual"] = (
        base_df["Actual_Output"] - base_df["Expected_Output"]
    )

    print("   ÊïàÁéáÊ®°ÂûãËÆ°ÁÆóÂÆåÊàê:")
    print(
        f"   -> È´òÊïàÁêÉÂëò (Efficiency > 1.1): {len(base_df[base_df['Efficiency'] > 1.1])}"
    )
    print(
        f"   -> ‰ΩéÊïàÁêÉÂëò (Efficiency < 0.9): {len(base_df[base_df['Efficiency'] < 0.9])}"
    )

    print(
        f"\n   ËßíËâ≤ÂàÜÂ∏É: Guards={len(base_df[base_df['ROLE'] == 'Guards'])}, Frontcourt={len(base_df[base_df['ROLE'] == 'Frontcourt'])}"
    )

    # =============================================================================
    # 2025-26 ËµõÂ≠£ÁâπÊÆäÂ§ÑÁêÜ: ‰∏∫ Hansen Yang ÂçïÁã¨ËÆ°ÁÆó EDI (ÂøΩÁï• GP ÈôêÂà∂)
    # =============================================================================
    if target_season == "2025-26":
        hansen_mask = d4_df["PLAYER_NAME"].str.contains("Hansen", case=False, na=False)
        if (
            hansen_mask.any()
            and not base_df["PLAYER_NAME"]
            .str.contains("Hansen", case=False, na=False)
            .any()
        ):
            print("\n   [ÁâπÊÆäÂ§ÑÁêÜ] ‰∏∫ Hansen Yang ËÆ°ÁÆó EDI (ÂøΩÁï• GP ÈôêÂà∂)...")

            # Ëé∑Âèñ Hansen ÁöÑÂü∫Á°ÄÊï∞ÊçÆ
            hansen_base = (
                d4_df[hansen_mask]
                .copy()[["PLAYER_ID", "PLAYER_NAME", "GP", "MIN", "PF", "STL", "BLK"]]
                .iloc[0:1]
            )

            # Ëé∑Âèñ‰ΩçÁΩÆ‰ø°ÊÅØ
            hansen_id = hansen_base["PLAYER_ID"].values[0]
            hansen_base["PLAYER_POSITION"] = "F"  # ÂâçÈîã
            hansen_base["ROLE"] = "Frontcourt"

            # D4: Defensive IQ
            hansen_base["Stocks"] = hansen_base["STL"] + hansen_base["BLK"]
            hansen_base["D4_Ratio"] = hansen_base["Stocks"] / (hansen_base["PF"] + 1)
            # ‰ΩøÁî®ËÅîÁõüÊéíÂêçËÆ°ÁÆóÁôæÂàÜ‰Ωç
            all_d4_ratios = d4_df["STL"] + d4_df["BLK"]
            all_d4_ratios = all_d4_ratios / (d4_df["PF"] + 1)
            hansen_d4_raw = (all_d4_ratios < hansen_base["D4_Ratio"].values[0]).mean()
            hansen_d4_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
            hansen_base["D4_Score"] = (hansen_d4_n * hansen_d4_raw + C * 0.5) / (
                hansen_d4_n + C
            )
            hansen_base["W4"] = hansen_d4_n / (hansen_d4_n + C)

            # D1: Shot Suppression (Value Added + MD Adjustment)
            if not d1_df.empty and hansen_id in d1_df["PLAYER_ID"].values:
                hansen_d1 = d1_df[d1_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_dfg = hansen_d1["D_FG_PCT"]
                hansen_dfga = hansen_d1["D_FGA"]
                hansen_pct_plusminus = hansen_d1["PCT_PLUSMINUS"]

                # Get Hansen's MD (if available)
                hansen_md_zscore = 0.0  # Default neutral
                if not md_df.empty and hansen_id in md_df["PLAYER_ID"].values:
                    hansen_md_row = md_df[md_df["PLAYER_ID"] == hansen_id].iloc[0]
                    hansen_md_zscore = hansen_md_row["MD_Zscore"]
                    hansen_base["MATCHUP_DIFFICULTY"] = hansen_md_row[
                        "MATCHUP_DIFFICULTY"
                    ]
                    hansen_base["MD_Zscore"] = hansen_md_zscore
                    hansen_base["MD_Percentile"] = hansen_md_row["MD_Percentile"]
                else:
                    hansen_base["MATCHUP_DIFFICULTY"] = 24.0
                    hansen_base["MD_Zscore"] = 0.0
                    hansen_base["MD_Percentile"] = 0.5

                # Apply MD adjustment: Adjusted_VA = PCT_PLUSMINUS * (1 + k * MD_Zscore)
                MD_K = 0.3
                hansen_pct_plusminus_adj = hansen_pct_plusminus * (
                    1 + MD_K * hansen_md_zscore
                )

                # Use adjusted PCT_PLUSMINUS to calculate percentile
                # Calculate adjusted VA for all players in d1_df for comparison
                if not md_df.empty:
                    d1_with_md = d1_df.merge(
                        md_df[["PLAYER_ID", "MD_Zscore"]], on="PLAYER_ID", how="left"
                    )
                    d1_with_md["MD_Zscore"] = d1_with_md["MD_Zscore"].fillna(0)
                    d1_with_md["PCT_PLUSMINUS_ADJ"] = d1_with_md["PCT_PLUSMINUS"] * (
                        1 + MD_K * d1_with_md["MD_Zscore"]
                    )
                    hansen_d1_raw = (
                        1
                        - (
                            d1_with_md["PCT_PLUSMINUS_ADJ"] < hansen_pct_plusminus_adj
                        ).mean()
                    )
                else:
                    hansen_d1_raw = (
                        1 - (d1_df["PCT_PLUSMINUS"] < hansen_pct_plusminus).mean()
                    )

                hansen_d1_n = hansen_dfga * hansen_base["GP"].values[0]
                hansen_base["D1_Score"] = (hansen_d1_n * hansen_d1_raw + C * 0.5) / (
                    hansen_d1_n + C
                )
                hansen_base["W1"] = hansen_d1_n / (hansen_d1_n + C)
                hansen_base["D_FG_PCT"] = hansen_dfg
                hansen_base["PCT_PLUSMINUS"] = hansen_pct_plusminus
                hansen_base["PCT_PLUSMINUS_ADJ"] = hansen_pct_plusminus_adj
            else:
                hansen_base["D1_Score"] = 0.5
                hansen_base["W1"] = 0.0
                hansen_base["D_FG_PCT"] = np.nan
                hansen_base["PCT_PLUSMINUS"] = np.nan
                hansen_base["PCT_PLUSMINUS_ADJ"] = np.nan
                hansen_base["MATCHUP_DIFFICULTY"] = 24.0
                hansen_base["MD_Zscore"] = 0.0
                hansen_base["MD_Percentile"] = 0.5

            # D2: Rim + 3PT (Frontcourt weights: ÂÜÖÁ∫ø60% / Â§ñÁ∫ø40%) - Value Added
            hansen_rim_raw, hansen_3pt_raw = 0.5, 0.5
            hansen_rim_fga, hansen_3pt_fga = 0, 0

            if not d2_rim_df.empty and hansen_id in d2_rim_df["PLAYER_ID"].values:
                hansen_rim = d2_rim_df[d2_rim_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_rim_dfg = hansen_rim["D_FG_PCT"]
                hansen_rim_plusminus = hansen_rim["PLUSMINUS"]
                # Value Added: PLUSMINUS Ë∂äË¥üË∂äÂ•Ω
                hansen_rim_raw = (
                    1 - (d2_rim_df["PLUSMINUS"] < hansen_rim_plusminus).mean()
                )
                hansen_rim_fga = hansen_rim.get("LT_06_FGA", 0)
                hansen_base["Rim_DFG"] = hansen_rim_dfg
                hansen_base["Rim_PLUSMINUS"] = hansen_rim_plusminus

            if not d2_3pt_df.empty and hansen_id in d2_3pt_df["PLAYER_ID"].values:
                hansen_3pt = d2_3pt_df[d2_3pt_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_3pt_dfg = hansen_3pt["D_FG_PCT"]
                hansen_3pt_plusminus = hansen_3pt["PLUSMINUS"]
                # Value Added: PLUSMINUS Ë∂äË¥üË∂äÂ•Ω
                hansen_3pt_raw = (
                    1 - (d2_3pt_df["PLUSMINUS"] < hansen_3pt_plusminus).mean()
                )
                hansen_3pt_fga = hansen_3pt.get("FG3A", 0)
                hansen_base["3PT_DFG"] = hansen_3pt_dfg
                hansen_base["3PT_PLUSMINUS"] = hansen_3pt_plusminus

            # Frontcourt: ÂÜÖÁ∫ø60% / Â§ñÁ∫ø40%
            hansen_d2_raw = hansen_rim_raw * 0.6 + hansen_3pt_raw * 0.4
            hansen_d2_n = (hansen_rim_fga * 0.6 + hansen_3pt_fga * 0.4) * hansen_base[
                "GP"
            ].values[0]
            hansen_base["D2_Score"] = (hansen_d2_n * hansen_d2_raw + C * 0.5) / (
                hansen_d2_n + C
            )
            hansen_base["W2"] = hansen_d2_n / (hansen_d2_n + C)

            # D3: Hustle Index
            if not d3_df.empty and hansen_id in d3_df["PLAYER_ID"].values:
                hansen_d3 = d3_df[d3_df["PLAYER_ID"] == hansen_id].iloc[0]
                defl = hansen_d3.get("DEFLECTIONS", 0)
                chrg = hansen_d3.get("CHARGES_DRAWN", 0)
                cont = hansen_d3.get("CONTESTED_SHOTS", 0)

                # ËÆ°ÁÆó Z-score Áõ∏ÂØπ‰∫éËÅîÁõü
                z_defl = (defl - d3_df["DEFLECTIONS"].mean()) / d3_df[
                    "DEFLECTIONS"
                ].std()
                z_chrg = (chrg - d3_df["CHARGES_DRAWN"].mean()) / d3_df[
                    "CHARGES_DRAWN"
                ].std()
                z_cont = (cont - d3_df["CONTESTED_SHOTS"].mean()) / d3_df[
                    "CONTESTED_SHOTS"
                ].std()
                hansen_hustle = z_defl + z_chrg * 2 + z_cont

                # ËÆ°ÁÆóÁôæÂàÜ‰Ωç
                all_hustle = (
                    d3_df["DEFLECTIONS"] - d3_df["DEFLECTIONS"].mean()
                ) / d3_df["DEFLECTIONS"].std()
                all_hustle += (
                    (d3_df["CHARGES_DRAWN"] - d3_df["CHARGES_DRAWN"].mean())
                    / d3_df["CHARGES_DRAWN"].std()
                    * 2
                )
                all_hustle += (
                    d3_df["CONTESTED_SHOTS"] - d3_df["CONTESTED_SHOTS"].mean()
                ) / d3_df["CONTESTED_SHOTS"].std()
                hansen_d3_raw = (all_hustle < hansen_hustle).mean()
                hansen_d3_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
                hansen_base["D3_Score"] = (hansen_d3_n * hansen_d3_raw + C * 0.5) / (
                    hansen_d3_n + C
                )
                hansen_base["W3"] = hansen_d3_n / (hansen_d3_n + C)
                hansen_base["DEFLECTIONS"] = defl
            else:
                hansen_base["D3_Score"] = 0.5
                hansen_base["W3"] = 0.0

            # D5: DREB%
            if not d5_adv_df.empty and hansen_id in d5_adv_df["PLAYER_ID"].values:
                hansen_dreb = d5_adv_df[d5_adv_df["PLAYER_ID"] == hansen_id][
                    "DREB_PCT"
                ].values[0]
                hansen_d5_raw = (d5_adv_df["DREB_PCT"] < hansen_dreb).mean()
                hansen_d5_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
                hansen_base["D5_Score"] = (hansen_d5_n * hansen_d5_raw + C * 0.5) / (
                    hansen_d5_n + C
                )
                hansen_base["W5"] = hansen_d5_n / (hansen_d5_n + C)  # Frontcourt: 1.0
                hansen_base["DREB_PCT"] = hansen_dreb
            else:
                hansen_base["D5_Score"] = 0.5
                hansen_base["W5"] = 0.0
                hansen_base["DREB_PCT"] = np.nan

            # ËÆ°ÁÆó EDI_Total (‰ΩøÁî®ÊïàÁéáÊ®°ÂûãÊ°ÜÊû∂)
            # Step 1: ËÆ°ÁÆóÂÆûÈôÖ‰∫ßÂá∫ (Actual Output)
            hansen_w1 = hansen_base["W1"].values[0]
            hansen_w2 = hansen_base["W2"].values[0]
            hansen_w3 = hansen_base["W3"].values[0]
            hansen_w4 = hansen_base["W4"].values[0]
            hansen_w5 = hansen_base["W5"].values[0]

            hansen_d1 = hansen_base["D1_Score"].values[0]
            hansen_d2 = hansen_base["D2_Score"].values[0]
            hansen_d3 = hansen_base["D3_Score"].values[0]
            hansen_d4 = hansen_base["D4_Score"].values[0]
            hansen_d5 = hansen_base["D5_Score"].values[0]

            hansen_actual_output = (hansen_d1 * hansen_w1 + hansen_d2 * hansen_w2) / (
                hansen_w1 + hansen_w2 + 1e-6
            )
            hansen_base["Actual_Output"] = hansen_actual_output

            # Step 2: ËÆ°ÁÆóÊäïÂÖ•ÂàÜ (Input Score)
            hansen_input_score = (hansen_d3 * hansen_w3 + hansen_d4 * hansen_w4) / (
                hansen_w3 + hansen_w4 + 1e-6
            )
            hansen_base["Input_Score"] = hansen_input_score

            # Step 3: Áî®Â∑≤ÊãüÂêàÁöÑÂõûÂΩíÊ®°ÂûãÈ¢ÑÊµãÈ¢ÑÊúü‰∫ßÂá∫
            if valid_mask.sum() > 10:
                hansen_expected_output = reg_model.predict([[hansen_input_score]])[0]
            else:
                hansen_expected_output = hansen_actual_output

            hansen_base["Expected_Output"] = hansen_expected_output

            # Step 4: ËÆ°ÁÆóÊïàÁéáÁ≥ªÊï∞ (ÈôêÂà∂Âú® [0.5, 1.5] ËåÉÂõ¥)
            hansen_efficiency = hansen_actual_output / (hansen_expected_output + 1e-6)
            hansen_efficiency = np.clip(hansen_efficiency, 0.5, 1.5)
            hansen_base["Efficiency"] = hansen_efficiency

            # Step 5: ËÆ°ÁÆóÊïàÁéáÊÆãÂ∑Æ
            hansen_base["Efficiency_Residual"] = (
                hansen_actual_output - hansen_expected_output
            )

            # Step 6: ËÆ°ÁÆó EDI (‰ΩøÁî®ÊïàÁéáÊ®°ÂûãÂÖ¨Âºè)
            output_weighted = (
                hansen_actual_output * hansen_efficiency * (hansen_w1 + hansen_w2)
            )
            input_weighted = hansen_input_score * (hansen_w3 + hansen_w4)
            d5_weighted = hansen_d5 * hansen_w5

            total_weight = hansen_w1 + hansen_w2 + hansen_w3 + hansen_w4 + hansen_w5
            hansen_base["EDI_Total"] = (
                (output_weighted + input_weighted + d5_weighted) / total_weight * 100
                if total_weight > 0
                else 50.0
            )

            print(
                f"   Hansen ÊïàÁéáÊ®°Âûã: Input={hansen_input_score:.3f}, Expected={hansen_expected_output:.3f}, Actual={hansen_actual_output:.3f}, Efficiency={hansen_efficiency:.3f}"
            )

            # Ê∑ªÂä†Âà∞ base_df
            base_df = pd.concat([base_df, hansen_base], ignore_index=True)
            print(
                f"   Hansen Yang EDI: {hansen_base['EDI_Total'].values[0]:.2f} (GP={hansen_base['GP'].values[0]})"
            )

    return base_df


# Helper to print top N with optional extra player
def print_top_n(df, title, n=5, extra_player=None, extra_label=None):
    if df.empty:
        return

    # Define column map and display columns first
    cn_col_map = {
        "PLAYER_NAME": "ÁêÉÂëò",
        "PLAYER_POSITION": "‰ΩçÁΩÆ",
        "EDI_Total": "Èò≤ÂÆàÁªüÊ≤ªÂäõ",
        "D1_Score": "ÂØπ‰ΩçÂéãÂà∂",
        "D2_Score": "ÂÜÖÂ§ñÂ∞ÅÈîÅ",
        "D3_Score": "Ê¥ªÂäõÊåáÊï∞",
        "D4_Score": "Èò≤ÂÆàÁêÉÂïÜ",
        "D5_Score": "ÁØÆÊùø‰øùÊä§",
        "Stocks": "Êä¢Êñ≠+ÁõñÂ∏Ω",
        "D4_Ratio": "ÁêÉÂïÜÊØîÂÄº",
        "DREB_PCT": "Èò≤ÂÆàÁØÆÊùø%",
        "D_FG_PCT": "ÂØπÊâãÂëΩ‰∏≠%",
        "PCT_PLUSMINUS": "ÂØπ‰ΩçÂéãÂà∂Â∑Æ%",
        "PCT_PLUSMINUS_ADJ": "MDË∞ÉÊï¥ÂéãÂà∂Â∑Æ%",
        "NORMAL_FG_PCT": "ÂØπÊâãÈ¢ÑÊúüÂëΩ‰∏≠%",
        "MATCHUP_DIFFICULTY": "ÂØπ‰ΩçÈöæÂ∫¶",
        "MD_Percentile": "ÂØπ‰ΩçÈöæÂ∫¶%",
        "Rim_DFG": "Êä§Á≠êÂëΩ‰∏≠%",
        "Rim_PLUSMINUS": "Êä§Á≠êÂéãÂà∂Â∑Æ%",
        "3PT_DFG": "‰∏âÂàÜÂëΩ‰∏≠%",
        "3PT_PLUSMINUS": "‰∏âÂàÜÂéãÂà∂Â∑Æ%",
        "DEFLECTIONS": "Âπ≤Êâ∞Ê¨°Êï∞",
        "PF": "ÁäØËßÑ",
        # ÊïàÁéáÊ®°ÂûãÁõ∏ÂÖ≥
        "Efficiency": "Èò≤ÂÆàÊïàÁéáÁ≥ªÊï∞",
        "Actual_Output": "ÂÆûÈôÖ‰∫ßÂá∫",
        "Expected_Output": "È¢ÑÊúü‰∫ßÂá∫",
        "Input_Score": "ÊäïÂÖ•ÂàÜ",
        "Efficiency_Residual": "ÊïàÁéáÊÆãÂ∑Æ",
    }

    display_cols = [
        "PLAYER_NAME",
        "PLAYER_POSITION",
        "EDI_Total",
        "D1_Score",
        "D2_Score",
        "D3_Score",
        "D4_Score",
        "D5_Score",
    ]

    total_count = len(df)
    print(f"\nüèÜ {title} Top {n}:")
    sorted_df = df.sort_values("EDI_Total", ascending=False)
    top_df = sorted_df.head(n)

    # If extra_player specified and not in top N, add them
    if extra_player:
        extra_mask = sorted_df["PLAYER_NAME"].str.contains(
            extra_player, case=False, na=False
        )
        if extra_mask.any():
            extra_row = sorted_df[extra_mask].iloc[0:1]
            # Check if already in top N
            if (
                not top_df["PLAYER_NAME"]
                .str.contains(extra_player, case=False, na=False)
                .any()
            ):
                # Calculate rank
                extra_rank = (
                    sorted_df["EDI_Total"] > extra_row["EDI_Total"].values[0]
                ).sum() + 1
                top_df = pd.concat([top_df, extra_row])
                print(f"   (ÂåÖÂê´ {extra_player}, ÊéíÂêç #{extra_rank}/{total_count})")

    # Filter display columns
    current_display_cols = [c for c in display_cols if c in df.columns]
    disp = top_df[current_display_cols].copy()
    disp = disp.rename(columns=cn_col_map)
    print(disp.round(2).to_string(index=False))
    return sorted_df  # Return for visualization


def create_individual_radar_charts(df, save_path, main_title="ÁêÉÂëòÈò≤ÂÆàËÉΩÂäõÁîªÂÉè"):
    """
    ‰∏∫ÊØè‰∏™ÁêÉÂëòÂàõÂª∫ÂçïÁã¨ÁöÑÈõ∑ËææÂõæÔºåÊ®™ÂêëÊéíÂàó
    ÂèÇËÄÉÂõæÁâáÊ†∑ÂºèÔºöÊØè‰∏™ÁêÉÂëò‰∏Ä‰∏™Â≠êÂõæÔºåÊòæÁ§∫ÁêÉÂëòÂêçÂíå EDI ÂàÜÊï∞
    """
    n_players = len(df)
    if n_players == 0:
        print("   WARNING: No players to plot")
        return

    # Dimension labels in Chinese
    categories = ["ÂØπ‰ΩçÂéãÂà∂", "ÂÜÖÂ§ñÂ∞ÅÈîÅ", "Ê¥ªÂäõÊåáÊï∞", "Èò≤ÂÆàÁêÉÂïÜ", "ÁØÆÊùø‰øùÊä§"]
    N = len(categories)

    # Compute angle for each axis
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1]  # Complete the loop

    # Color palette for each player (different colors)
    colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7", "#DDA0DD"]

    # Create figure with subplots (1 row, n_players columns)
    fig_width = 4 * n_players
    fig, axes = plt.subplots(
        1, n_players, figsize=(fig_width, 5), subplot_kw=dict(polar=True)
    )

    # Handle single player case
    if n_players == 1:
        axes = [axes]

    # Plot each player in their own subplot
    for idx, (_, row) in enumerate(df.iterrows()):
        ax = axes[idx]
        color = colors[idx % len(colors)]

        values = [
            row["D1_Score"],
            row["D2_Score"],
            row["D3_Score"],
            row["D4_Score"],
            row["D5_Score"],
        ]
        values += values[:1]  # Complete the loop

        # Plot the radar
        ax.plot(angles, values, "o-", linewidth=2, color=color)
        ax.fill(angles, values, alpha=0.25, color=color)

        # Set category labels
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, size=9, fontweight="bold")

        # Set y-axis limits (0 to 1 for percentile scores)
        ax.set_ylim(0, 1)
        ax.set_yticks([0.5, 1.0])
        ax.set_yticklabels(["50%", "100%"], size=8, color="gray")

        # Add gridlines
        ax.grid(True, linestyle="--", alpha=0.5)

        # Title with player name and EDI score
        ax.set_title(
            f"{row['PLAYER_NAME']}\nÈò≤ÂÆàÁªüÊ≤ªÂäõ: {row['EDI_Total']:.1f}",
            size=11,
            fontweight="bold",
            pad=15,
        )

    # Main title
    fig.suptitle(f"{main_title} ({SEASON})", size=16, fontweight="bold", y=1.05)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches="tight", facecolor="white")
    print(f"Â∑≤‰øùÂ≠ò: {save_path}")
    plt.close()


def plot_history_radar(history_df):
    """
    ÁªòÂà∂Â∫ìÈáåËÅå‰∏öÁîüÊ∂ØÈò≤ÂÆàÊºîÂèòÈõ∑ËææÂõæ (‰∏≠ÊñáÁâà)
    """
    import matplotlib

    matplotlib.rcParams["font.sans-serif"] = [
        "SimHei",
        "Microsoft YaHei",
        "Arial Unicode MS",
    ]
    matplotlib.rcParams["axes.unicode_minus"] = False

    if history_df.empty:
        return

    # ‰∫îÁª¥‰∏≠ÊñáÊ†áÁ≠æ
    categories = [
        "D1: ÂØπ‰ΩçÂéãÂà∂",
        "D2: ÂÜÖÂ§ñÂ∞ÅÈîÅ",
        "D3: Ê¥ªÂäõÊåáÊï∞",
        "D4: Èò≤ÂÆàÁêÉÂïÜ",
        "D5: ÁØÆÊùø‰øùÊä§",
    ]
    N = len(categories)

    # ËÆ°ÁÆóËßíÂ∫¶
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1]

    # ÂàùÂßãÂåñÂõæË°®
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))

    # ‰∏â‰∏™Èò∂ÊÆµÁöÑÊ†∑ÂºèÈÖçÁΩÆ
    styles = {
        "2016-17": {
            "color": "#FFC72C",  # ÂãáÂ£´ÈáëËâ≤
            "linestyle": "--",
            "linewidth": 2.5,
            "label": "2016-17 Â∑ÖÂ≥∞ÁéãÊúù",
            "alpha": 0.15,
        },
        "2021-22": {
            "color": "#1D428A",  # ÂãáÂ£´ËìùËâ≤
            "linestyle": "-.",
            "linewidth": 2.5,
            "label": "2021-22 ÁéãËÄÖÂΩíÊù•",
            "alpha": 0.15,
        },
        "2024-25": {
            "color": "#006BB6",  # NBAËìù
            "linestyle": "-",
            "linewidth": 3,
            "label": "2024-25 ËÄÅÂ∞ÜËµõÂ≠£",
            "alpha": 0.2,
        },
    }

    # ÁªòÂà∂ÊØè‰∏™ËµõÂ≠£
    for _, row in history_df.iterrows():
        season = row["SEASON_ID"]
        style = styles.get(
            season,
            {
                "color": "gray",
                "linestyle": "-",
                "linewidth": 1,
                "label": season,
                "alpha": 0.1,
            },
        )

        values = [
            row.get("D1_Score", 0.5),
            row.get("D2_Score", 0.5),
            row.get("D3_Score", 0.5),
            row.get("D4_Score", 0.5),
            row.get("D5_Score", 0.5),
        ]
        values = [0.5 if pd.isna(v) else v for v in values]
        values += values[:1]

        ax.plot(
            angles,
            values,
            color=style["color"],
            linestyle=style["linestyle"],
            linewidth=style["linewidth"],
            label=style["label"],
            marker="o",
            markersize=6,
        )
        ax.fill(angles, values, color=style["color"], alpha=style["alpha"])

    # ËÆæÁΩÆÊ†áÁ≠æ
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(categories, size=12, fontweight="bold")

    # ËÆæÁΩÆYËΩ¥
    ax.set_ylim(0, 1)
    ax.set_yticks([0.25, 0.5, 0.75, 1.0])
    ax.set_yticklabels(["25%", "50%", "75%", "100%"], size=9, color="gray")

    # Ê†áÈ¢òÂíåÂõæ‰æã
    plt.title(
        "ÊñØËíÇËä¨¬∑Â∫ìÈáåÔºöÈò≤ÂÆàËÉΩÂäõÊºîÂèò\n(Â∑ÖÂ≥∞ÁéãÊúù vs ÁéãËÄÖÂΩíÊù• vs ËÄÅÂ∞ÜËµõÂ≠£)",
        size=16,
        fontweight="bold",
        y=1.1,
    )
    plt.legend(loc="upper right", bbox_to_anchor=(1.35, 1.1), fontsize=11)

    # ‰øùÂ≠ò
    save_path = FIGURES_DIR / "nba_defense_curry_history.png"
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches="tight", facecolor="white")
    print(f"Â∑≤‰øùÂ≠ò: {save_path}")
    plt.close()


if __name__ == "__main__":
    if HISTORY_MODE:
        print(f"=== NBA Defense MVP Analysis (History Mode: Curry Eras) ===")
        target_seasons = ["2016-17", "2021-22", "2024-25"]
        curry_id = 201939
        history_results = []

        for s in target_seasons:
            try:
                # Use a larger timeout or retry logic handled inside analyze_season/get_league_data
                season_df = analyze_season(s)

                if not season_df.empty:
                    # Find Curry
                    curry_data = season_df[season_df["PLAYER_ID"] == curry_id]
                    if not curry_data.empty:
                        row = curry_data.iloc[0].to_dict()
                        row["SEASON_ID"] = s
                        history_results.append(row)
                        print(
                            f"   -> Found Curry in {s}: EDI={row.get('EDI_Total', 0):.1f}"
                        )
                    else:
                        print(f"   -> WARNING: Stephen Curry not found in {s}")
                        # Append empty/default row to keep structure? Or just skip?
                        # Let's append a row with 0s/NaNs so we know we tried
                        empty_row = {col: np.nan for col in season_df.columns}
                        empty_row["PLAYER_NAME"] = "Stephen Curry"
                        empty_row["PLAYER_ID"] = curry_id
                        empty_row["SEASON_ID"] = s
                        history_results.append(empty_row)
            except Exception as e:
                print(f"   ERROR analyzing {s}: {e}")

        # Summary Table
        if history_results:
            history_df = pd.DataFrame(history_results)

            # Reorder columns for readability
            cols_order = [
                "SEASON_ID",
                "PLAYER_NAME",
                "EDI_Total",
                "D1_Score",
                "D2_Score",
                "D3_Score",
                "D4_Score",
                "D5_Score",
                "Efficiency",
                "Actual_Output",
                "Expected_Output",
            ]
            # Filter to exist cols
            cols_order = [c for c in cols_order if c in history_df.columns]

            print("\n" + "=" * 60)
            print("üèÄ Stephen Curry: Career Defense Evolution (3 Eras)")
            print("=" * 60)
            print(history_df[cols_order].round(2).to_string(index=False))

            # Save
            history_df.to_csv(DATA_DIR / "nba_defense_curry_history.csv", index=False)
            print(
                f"\nüìÅ History saved to: {DATA_DIR / 'nba_defense_curry_history.csv'}"
            )

            # Plot
            plot_history_radar(history_df)

    else:
        print(f"=== NBA Defense MVP Analysis ({SEASON}) ===")
        print(f"Target Players: {TARGET_PLAYERS}\n")

        # Call the encapsulated function
        base_df = analyze_season(SEASON)

        # =============================================================================
        # STEP 3: FILTER TARGET PLAYERS & RANKING
        # =============================================================================
        if not base_df.empty:
            # Filter for specific target players for the radar chart
            final_results = []
            for target in TARGET_PLAYERS:
                match_mask = (
                    base_df["PLAYER_NAME"].astype(str).str.contains(target, case=False)
                )
                match = base_df[match_mask]
                if not match.empty:
                    final_results.append(match.iloc[0])
                else:
                    print(f"   WARNING: Could not find data for {target}")

            results_df = pd.DataFrame(final_results)

            # =============================================================================
            # STEP 4: OUTPUT RESULTS
            # =============================================================================

            print("\n" + "=" * 80)
            print("                    üèÄ NBA Èò≤ÂÆàÁªüÊ≤ªÂäõÊéíË°åÊ¶ú üèÄ")
            print("=" * 80)
            print(
                "\nüìä „ÄêÊ®°ÂûãÊñπÊ≥ïËÆ∫„ÄëË¥ùÂè∂ÊñØ‰∫îÁª¥Èò≤ÂÆàËØÑ‰º∞Ê°ÜÊû∂ (Bayesian 5-Dimension Defensive Evaluation)"
            )
            print(
                "   Ê†∏ÂøÉÊÄùÊÉ≥: Â∞ÜÈò≤ÂÆàÊãÜËß£‰∏∫5‰∏™Áã¨Á´ãÁª¥Â∫¶ÔºåÊØè‰∏™Áª¥Â∫¶‰ΩøÁî®ÁôæÂàÜ‰ΩçÊéíÂêç(0-100%)‰Ωú‰∏∫ÂÖàÈ™åÊ¶ÇÁéáÔºå"
            )
            print(
                '             ÈÄöËøáË¥ùÂè∂ÊñØÊî∂Áº©Ë∞ÉÊï¥ÂêéÔºå‰ΩøÁî®ÊïàÁéáÊ®°ÂûãÊ°ÜÊû∂Âä†ÊùÉÂπ≥ÂùáÂæóÂá∫"Èò≤ÂÆàÁªüÊ≤ªÂäõ"ÊåáÊï∞„ÄÇ'
            )
            print("\nüìä Ë¥ùÂè∂ÊñØÈÄªËæë:")
            print("   ‚Ä¢ ÂÖàÈ™åÂàÜÂ∏É: ÊØè‰∏™Áª¥Â∫¶ÁöÑËÅîÁõüÂàÜÂ∏É‰Ωú‰∏∫ÂÖàÈ™å (Prior)")
            print("   ‚Ä¢ ‰ººÁÑ∂ÂáΩÊï∞: ÁêÉÂëòÂÆûÈôÖË°®Áé∞Êï∞ÊçÆ‰Ωú‰∏∫‰ººÁÑ∂ (Likelihood)")
            print("   ‚Ä¢ ÂêéÈ™å‰º∞ËÆ°: D_k = (n √ó raw_pct + C √ó 0.5) / (n + C)")
            print(f"   ‚Ä¢ Êî∂Áº©Â∏∏Êï∞: C = {BAYES_C} (Ê†∑Êú¨ÈáèËææÂà∞ C Êó∂ÔºåÊï∞ÊçÆÊùÉÈáç = 50%)")
            print("\nüìä ÊïàÁéáÊ®°ÂûãÊ°ÜÊû∂ (Efficiency Model Framework):")
            print(
                "   ‚Ä¢ ÊäïÂÖ•Â±Ç (Input): D3 (Ê¥ªÂäõÊåáÊï∞) + D4 (Èò≤ÂÆàÁêÉÂïÜ) - ÂΩ±ÂìçÈò≤ÂÆàÁªìÊûúÁöÑÂä™Âäõ/ÊñπÂºè"
            )
            print(
                "   ‚Ä¢ ‰∫ßÂá∫Â±Ç (Output): D1 (ÂØπ‰ΩçÂéãÂà∂) + D2 (ÂÜÖÂ§ñÂ∞ÅÈîÅ) - Èò≤ÂÆàÁöÑÁõ¥Êé•ÁªìÊûú"
            )
            print("   ‚Ä¢ Áã¨Á´ãÂ±Ç: D5 (ÁØÆÊùø‰øùÊä§) - ‰∏çÂèÇ‰∏éÊïàÁéáËÆ°ÁÆó")
            print("   ‚Ä¢ ÂõûÂΩíÊ®°Âûã: Expected_Output = Œ± + Œ≤ √ó Input_Score")
            print(
                "   ‚Ä¢ ÊïàÁéáÁ≥ªÊï∞: Efficiency = Actual_Output / Expected_Output (ÈôêÂà∂Âú® 0.5-1.5)"
            )
            print(
                "   ‚Ä¢ EDIÂÖ¨Âºè: EDI = [Output√óEfficiency√ó(W1+W2) + Input√ó(W3+W4) + D5√óW5] / ÊÄªÊùÉÈáç"
            )
            print("   ‚Ä¢ È´òÊïàÁêÉÂëò: ÊäïÂÖ•Â∞ë‰ΩÜ‰∫ßÂá∫È´ò (Â§©Ëµã/Èò≤ÂÆàÊô∫ÊÖß) ‚Üí Efficiency > 1.0")
            print("   ‚Ä¢ ‰ΩéÊïàÁêÉÂëò: ÊäïÂÖ•Â§ö‰ΩÜ‰∫ßÂá∫‰Ωé (Á©∫ÊúâÂä™Âäõ) ‚Üí Efficiency < 1.0")
            print("\nüìä ËßíËâ≤Áõ∏ÂÖ≥ÊÄßÁ≥ªÊï∞ (Role Relevance Coefficient):")
            print("   ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê")
            print("   ‚îÇ ËßíËâ≤        ‚îÇ D2 ÂÜÖÂ§ñÂ∞ÅÈîÅÊùÉÈáç           ‚îÇ D5 ÁØÆÊùøÊùÉÈáçÁ≥ªÊï∞ ‚îÇ")
            print("   ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§")
            print("   ‚îÇ Guards (G)  ‚îÇ Â§ñÁ∫ø60% / ÂÜÖÁ∫ø40%         ‚îÇ 0.5 (Ë°∞Âáè50%)   ‚îÇ")
            print("   ‚îÇ Frontcourt  ‚îÇ Â§ñÁ∫ø40% / ÂÜÖÁ∫ø60%         ‚îÇ 1.0 (ÂÆåÊï¥‰øùÁïô)  ‚îÇ")
            print("   ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò")
            print("\nüìä ‰∫îÁª¥ËØ¥Êòé (Value Added + Matchup Difficulty ÊîπËøõÁâà):")
            print(
                "   | D1 ÂØπ‰ΩçÂéãÂà∂: PCT_PLUSMINUS √ó (1 + 0.3 √ó MD_Zscore) | MDË∞ÉÊï¥ÔºöÈò≤ÂÆàÂº∫‰∫∫Âä†ÂàÜÔºåË∫≤ÈÅøÈò≤ÂÆàÂáèÂàÜ |"
            )
            print(
                "   | D2 ÂÜÖÂ§ñÂ∞ÅÈîÅ: PLUSMINUS (Êä§Á≠ê+‰∏âÂàÜÔºåÊåâËßíËâ≤Âä†ÊùÉ) | ÂêåÊ†∑‰ΩøÁî® Value Added ÊñπÊ≥ï |"
            )
            print(
                "   | D3 Ê¥ªÂäõÊåáÊï∞: Âπ≤Êâ∞ÁêÉ + ÈÄ†ËøõÊîªÁäØËßÑ√ó2 + Âπ≤Êâ∞ÊäïÁØÆ (Z-Score) | Êï∞ÊçÆÊ∫ê: LeagueHustleStatsPlayer |"
            )
            print(
                '   | D4 Èò≤ÂÆàÁêÉÂïÜ: (Êä¢Êñ≠ + ÁõñÂ∏Ω) / (ÁäØËßÑ + 1) | ÊïàÁéáÂûãÊåáÊ†áÔºåÊÉ©ÁΩö"Á´ôÊ°©Âûã"‰ΩéÁäØËßÑÁêÉÂëò |'
            )
            print(
                "   | D5 ÁØÆÊùø‰øùÊä§: Èò≤ÂÆàÁØÆÊùøÁéá (DREB%) | Êï∞ÊçÆÊ∫ê: LeagueDashPlayerStats (Advanced) |"
            )
            print("\nüìä Matchup Difficulty (MD) ÂØπ‰ΩçÈöæÂ∫¶Ë∞ÉÊï¥:")
            print("   ‚Ä¢ Êï∞ÊçÆÊ∫ê: LeagueSeasonMatchups (ÊØèÂØπÊîªÈò≤ÁêÉÂëòÁöÑÂõûÂêàÊï∞ÊçÆ)")
            print(
                "   ‚Ä¢ ËÆ°ÁÆóÊñπÊ≥ï: ÊØè‰ΩçËøõÊîªÁêÉÂëòÁöÑ PTS/100ÂõûÂêà ‚Üí ÊØè‰ΩçÈò≤ÂÆàËÄÖÁöÑÂØπ‰ΩçÈöæÂ∫¶Âä†ÊùÉÂπ≥Âùá"
            )
            print("   ‚Ä¢ MD_Zscore > 0: Èò≤ÂÆàÂº∫ÂæóÂàÜÊâã (Â¶ÇDillon BrooksÈò≤ÂÆàCurry)")
            print("   ‚Ä¢ MD_Zscore < 0: Ë∫≤ÈÅøÂº∫ÂæóÂàÜÊâã (Â¶ÇCurryÈò≤ÂÆàÂº±‰æßÁøº)")
            print("   ‚Ä¢ D1Ë∞ÉÊï¥: Adjusted_VA = PCT_PLUSMINUS √ó (1 + 0.3 √ó MD_Zscore)")
            print(
                "   ‚Ä¢ Á§∫‰æã: -5%ÂéãÂà∂Â∑Æ + MD_Zscore=1 ‚Üí -6.5% (Â•ñÂä±); MD_Zscore=-2 ‚Üí -2% (ÊÉ©ÁΩö)"
            )
            print("\nüìä Value Added ÊîπËøõËØ¥Êòé:")
            print("   ‚Ä¢ Ëß£ÂÜ≥ÈóÆÈ¢ò: Èò≤ÂÆà‰ΩéÊïàÊäïÊâã(Â¶ÇÂ∫ïËßíÂ∞ÑÊâã)Ëé∑ÂæóÈ´òÂàÜÁöÑÈóÆÈ¢ò")
            print("   ‚Ä¢ ÊîπËøõÊñπÊ≥ï: ‰ΩøÁî® PCT_PLUSMINUS = D_FG_PCT - NORMAL_FG_PCT")
            print("   ‚Ä¢ Ëß£ËØª: ËÆ©ÂØπÊâãÊØî‰ªñÈ¢ÑÊúüÂëΩ‰∏≠Áéá‰ΩéÂ§öÂ∞ëÔºåËÄåÈùûÂéüÂßãÂëΩ‰∏≠Áéá")
            print(
                "   ‚Ä¢ Á§∫‰æã: ËÆ©50%ÂëΩ‰∏≠ÁéáÁêÉÂëòÈôçÂà∞45% (VA=-5%) > ËÆ©40%ÁêÉÂëòÁª¥ÊåÅ40% (VA=0%)"
            )
            print("-" * 80)

            # League Top 5
            league_sorted = print_top_n(base_df, "ËÅîÁõü (League)", n=5)

            # Positional Rankings
            guards = base_df[
                base_df["PLAYER_POSITION"].str.contains("G", na=False)
                & ~base_df["PLAYER_POSITION"].str.contains("F", na=False)
            ]  # Á∫ØÂêéÂç´
            frontcourt = base_df[base_df["ROLE"] == "Frontcourt"]  # ÂâçÂú∫ (Âê´FÊàñC)

            # ÂêéÂç´ Top 5 + Curry
            guards_sorted = print_top_n(
                guards,
                "ÂêéÂç´ (Guards)",
                n=5,
                extra_player="Stephen Curry",
                extra_label="Curry",
            )
            # ÂâçÂú∫ Top 5 + Hansen Yang (‰ªÖ 2025-26 ËµõÂ≠£)
            if SEASON == "2025-26":
                print_top_n(
                    frontcourt,
                    "ÂâçÂú∫ (Frontcourt)",
                    n=5,
                    extra_player="Hansen",
                    extra_label="Hansen Yang",
                )
            else:
                print_top_n(frontcourt, "ÂâçÂú∫ (Frontcourt)", n=5)

            # Save all data to CSV
            base_df.to_csv(
                DATA_DIR / f"nba_defensive_all_players_{SEASON}.csv", index=False
            )
            print(
                f"\nüìÅ Â∑≤‰øùÂ≠ò: {DATA_DIR / f'nba_defensive_all_players_{SEASON}.csv'} (ÂÖ®ÈÉ®ÁêÉÂëò)"
            )

            if not results_df.empty:
                results_df = results_df.sort_values("EDI_Total", ascending=False)
                results_df.to_csv(
                    DATA_DIR / f"nba_defensive_mvp_results_{SEASON}.csv", index=False
                )
                print(
                    f"üìÅ Â∑≤‰øùÂ≠ò: {DATA_DIR / f'nba_defensive_mvp_results_{SEASON}.csv'} (ÁõÆÊ†áÁêÉÂëò)"
                )

            # =============================================================================
            # STEP 5: RADAR CHART VISUALIZATION (ÊØè‰∏™ÁêÉÂëòÂçïÁã¨‰∏Ä‰∏™Èõ∑ËææÂõæ)
            # =============================================================================
            print("\nÁîüÊàêÈõ∑ËææÂõæ...")

            # Configure matplotlib for Chinese font support
            plt.rcParams["font.sans-serif"] = [
                "Microsoft YaHei",
                "SimHei",
                "DejaVu Sans",
            ]
            plt.rcParams["axes.unicode_minus"] = False

            # ËÅîÁõü Top 5 ÂçïÁã¨Èõ∑ËææÂõæ
            league_top5 = base_df.sort_values("EDI_Total", ascending=False).head(5)
            create_individual_radar_charts(
                league_top5,
                FIGURES_DIR / f"nba_defense_league_top5_{SEASON}.png",
                "ËÅîÁõü Top 5 Èò≤ÂÆàËÉΩÂäõÁîªÂÉè",
            )

            # ÂêéÂç´ Top 5 + Curry ÂçïÁã¨Èõ∑ËææÂõæ
            guards_sorted = guards.sort_values("EDI_Total", ascending=False)
            guard_top5 = guards_sorted.head(5)
            guards_total = len(guards_sorted)

            # Ê∑ªÂä† Curry (Â¶ÇÊûú‰∏çÂú® Top 5 ‰∏≠)
            curry_mask = guards_sorted["PLAYER_NAME"].str.contains(
                "Stephen Curry", case=False, na=False
            )
            if curry_mask.any():
                curry_row = guards_sorted[curry_mask].iloc[0:1]
                if (
                    not guard_top5["PLAYER_NAME"]
                    .str.contains("Stephen Curry", case=False, na=False)
                    .any()
                ):
                    curry_rank = (
                        guards_sorted["EDI_Total"] > curry_row["EDI_Total"].values[0]
                    ).sum() + 1
                    guard_top5 = pd.concat([guard_top5, curry_row])
                    curry_note = f" (Âê´Curry #{curry_rank}/{guards_total})"
                else:
                    curry_note = ""
            else:
                curry_note = " (CurryÊú™ÊâæÂà∞)"

            create_individual_radar_charts(
                guard_top5,
                FIGURES_DIR / f"nba_defense_guard_top5_{SEASON}.png",
                f"ÂêéÂç´ Top 5 Èò≤ÂÆàËÉΩÂäõÁîªÂÉè{curry_note}",
            )

            # ÂâçÂú∫ Top 5 ÂçïÁã¨Èõ∑ËææÂõæ (2025-26 ËµõÂ≠£ÂåÖÂê´ Hansen Yang)
            # ‰ΩøÁî® Frontcourt (ROLE == "Frontcourt"ÔºåÂåÖÂê´FÂíåC)
            frontcourt_sorted = base_df[base_df["ROLE"] == "Frontcourt"].sort_values(
                "EDI_Total", ascending=False
            )
            frontcourt_top5 = frontcourt_sorted.head(5)
            frontcourt_total = len(frontcourt_sorted)

            # 2025-26 ËµõÂ≠£Ê∑ªÂä† Hansen Yang (Â¶ÇÊûú‰∏çÂú® Top 5 ‰∏≠)
            hansen_note = ""
            if SEASON == "2025-26":
                hansen_mask = frontcourt_sorted["PLAYER_NAME"].str.contains(
                    "Hansen", case=False, na=False
                )
                if hansen_mask.any():
                    hansen_row = frontcourt_sorted[hansen_mask].iloc[0:1]
                    if (
                        not frontcourt_top5["PLAYER_NAME"]
                        .str.contains("Hansen", case=False, na=False)
                        .any()
                    ):
                        hansen_rank = (
                            frontcourt_sorted["EDI_Total"]
                            > hansen_row["EDI_Total"].values[0]
                        ).sum() + 1
                        frontcourt_top5 = pd.concat([frontcourt_top5, hansen_row])
                        hansen_note = f" (Âê´Hansen #{hansen_rank}/{frontcourt_total})"
                else:
                    hansen_note = " (HansenÊú™ÊâæÂà∞)"

            create_individual_radar_charts(
                frontcourt_top5,
                FIGURES_DIR / f"nba_defense_frontcourt_top5_{SEASON}.png",
                f"ÂâçÂú∫ Top 5 Èò≤ÂÆàËÉΩÂäõÁîªÂÉè{hansen_note}",
            )

            print("\n[ÂÆåÊàê] ÂàÜÊûêÁªìÊùü!")
