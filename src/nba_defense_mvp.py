"""
NBA Defensive Impact (EDI) - MVP Analysis Script
=================================================
Analyzes 5 defensive dimensions and outputs radar charts.

Usage:
    python src/nba_defense_mvp.py           # Default: 2024-25 season
    python src/nba_defense_mvp.py 2025-26   # Specify season
"""

import sys
import io
import pandas as pd
import numpy as np
import time
from pathlib import Path

import matplotlib.pyplot as plt
from scipy import stats
from nba_api.stats.endpoints import (
    leaguedashptdefend,
    leaguehustlestatsplayer,
    leaguedashplayerstats,
    leagueseasonmatchups,
    leaguedashplayerbiostats,
    commonteamroster,
    commonallplayers,
)
from nba_api.stats.static import teams
from sklearn.linear_model import LinearRegression

# Fix Windows console encoding for Chinese characters
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding="utf-8", errors="replace")

# --- Configuration ---
HISTORY_MODE = False
if len(sys.argv) > 1:
    if sys.argv[1] == "--history":
        HISTORY_MODE = True
        SEASON = "2024-25"
    else:
        SEASON = sys.argv[1]
else:
    SEASON = "2024-25"

BASE_DIR = Path(__file__).resolve().parent.parent
DATA_DIR = BASE_DIR / "data"
FIGURES_DIR = BASE_DIR / "figures"
DATA_DIR.mkdir(parents=True, exist_ok=True)
FIGURES_DIR.mkdir(parents=True, exist_ok=True)

TARGET_PLAYERS = [
    "Bam Adebayo",
    "Rudy Gobert",
    "Jrue Holiday",
    "Victor Wembanyama",
    "Trae Young",
]

# MIN_GP å°†åœ¨æ•°æ®è·å–ååŠ¨æ€è®¡ç®— (å½“å‰èµ›å­£æœ€å¤§æ¯”èµ›åœºæ¬¡çš„ä¸€åŠ)
MIN_MIN = 15

# è´å¶æ–¯æ”¶ç¼©å¸¸æ•°
BAYES_C = 60  # æ”¶ç¼©å¼ºåº¦ï¼šæ ·æœ¬é‡è¾¾åˆ° C æ—¶ï¼Œæ•°æ®æƒé‡ = 50%

# Sigmoid å¯ç”¨æ€§å‚æ•° (Availability Sigmoid)
# ç”¨äºæƒ©ç½šä½å‡ºåœºçƒå‘˜ï¼ŒåŒæ—¶é˜²æ­¢é“äººåˆ·åˆ†
SIGMOID_G0 = 45  # Sigmoid ä¸­ç‚¹ (åœºæ¬¡é˜ˆå€¼)
SIGMOID_K = 0.15  # Sigmoid æ–œç‡

# Roamer åŠ¨æ€æƒé‡è°ƒèŠ‚ç³»æ•° (Roamer Dynamic Weight Adjustment)
# ç”¨äºè¯†åˆ«"æ‰«è¡å‹å†…çº¿"(å¦‚ JJJ)ï¼Œé™ä½å…¶ç¯®æ¿æƒé‡å’Œå¤–çº¿é˜²å®ˆæƒé‡
# Roamer_Index = BLK_per_36 / (DREB_PCT + 0.01)
# W5_Adjusted = W5_Base * D5_IMPACT * (1 - ROAMER_K * Roamer_Percentile)
ROAMER_K = 0.3  # D5 çµæ•åº¦ï¼š0.3 è¡¨ç¤ºæœ€æç«¯çš„æ‰«è¡è€… D5 æƒé‡é™è‡³ 0.7

# Roamer åˆ†ç±»é˜ˆå€¼ (Roamer Classification Threshold)
# Frontcourt çƒå‘˜ Roamer_Pct >= ROAMER_THRESHOLD æ—¶è¢«åˆ†ç±»ä¸º Roamer
# [2025-01-17 ä¼˜åŒ–ç»“æœ: 0.15 é˜ˆå€¼è¦†ç›–ä¸»è¦æ‰«è¡å‹å†…çº¿]
ROAMER_THRESHOLD = 0.15  # 15th ç™¾åˆ†ä½ä»¥ä¸Šè§†ä¸º Roamer

# Roamer æƒé‡é‡åˆ†é…ç³»æ•° (Roamer Weight Redistribution)
# å°† Roamer çƒå‘˜å›  D5 é™æƒè€Œå¤±å»çš„æƒé‡ï¼Œé‡æ–°åˆ†é…åˆ°å…¶è¡¨ç°çªå‡ºçš„ç»´åº¦
# è¿™ä½“ç°äº†"èŒè´£åˆ†å·¥"çš„å…¬å¹³æ€§ï¼šæ‰«è¡è€…ç‰ºç‰²ç¯®æ¿æ¢å–åé˜²ï¼Œåº”è·å¾—ç›¸åº”è¡¥å¿
# åˆ†é…ç­–ç•¥: 30% è¡¥ç»™äº§å‡ºå±‚ (W1+W2)ï¼Œ70% è¡¥ç»™æ´»åŠ›å±‚ (W3)
# [2025-01-17 ä¼˜åŒ–ç»“æœ: DPOY Avg Rank=2.80, Recall@30=35/50, JJJ Roamer #6]
ROAMER_WEIGHT_REDIST_OUTPUT = 0.3  # åˆ†é…ç»™äº§å‡ºå±‚ (D1/D2) çš„æ¯”ä¾‹
ROAMER_WEIGHT_REDIST_HUSTLE = 0.7  # åˆ†é…ç»™æ´»åŠ›å±‚ (D3) çš„æ¯”ä¾‹

# D2 å¤–çº¿æƒé‡è°ƒæ•´ç³»æ•° (D2 Exterior Weight Adjustment for Roamers)
# Roamer çƒå‘˜ä¸»è¦æŠ¤ç­ï¼Œå¤–çº¿é˜²å®ˆæ ·æœ¬å°‘ä¸”ä¸ä»£è¡¨å…¶ä»·å€¼
# adjusted_ext = base_ext * (1 - D2_EXT_ROAMER_K * Roamer_Pct)
# Roamer_Pct=1.0: å¤–çº¿æƒé‡ä» 45% é™è‡³ 22.5%
# Roamer_Pct=0.0: å¤–çº¿æƒé‡ä¿æŒ 45%
D2_EXT_ROAMER_K = 0.5  # æœ€å¤§é™ä½ 50% çš„å¤–çº¿æƒé‡

# =============================================================================
# ååŒæ•ˆåº”åŠ åˆ† (Synergy Bonus for Switchable Defenders)
# =============================================================================
# å¥–åŠ±"æ¢é˜²å…¨èƒ½å‹"é˜²å®ˆè€…ï¼šå†…çº¿èƒ½æŠ¤ç­ + å¤–çº¿ä¹Ÿèƒ½é˜²
# å…¸å‹ä»£è¡¨: JJJ, Anthony Davis, Bam Adebayo, Wembanyama
# è®¾è®¡ç†å¿µ: åŸºäº D1 (å¯¹ä½å‹åˆ¶) å’Œ D2 (å†…å¤–å°é”) çš„çœŸå®é˜²å®ˆæ•ˆæœ
#           è€Œé D3/D4 çš„"æŠ•å…¥æŒ‡æ ‡"ï¼Œé¿å…å¥–åŠ±åƒåº“é‡Œè¿™ç§é«˜æ´»åŠ›ä½†æ•ˆæœä¸€èˆ¬çš„çƒå‘˜
# å…¬å¼ (å¹³æ–¹æ ¹ç‰ˆï¼Œå‰Šå³°å¡«è°·):
#   if D1 >= T1 and D2 >= T2:
#       Synergy_Bonus = sqrt((D1 - T1) * (D2 - T2)) * SYNERGY_FACTOR * 100
# å¹³æ–¹æ ¹é€»è¾‘: ç¼“è§£é©¬å¤ªæ•ˆåº”ï¼Œè®©"å‡†é¡¶çº§å…¨èƒ½è€…"ä¹Ÿèƒ½è·å¾—åˆç†åŠ åˆ†
# [2025-01-17 ä¼˜åŒ–ç»“æœ: D1=0.80, D2=0.75, SF=0.5 å®ç°æœ€ä½³å¹³è¡¡]
SYNERGY_D1_THRESHOLD = 0.80  # D1 (å¯¹ä½å‹åˆ¶) é˜ˆå€¼ï¼Œçº¦ 80th ç™¾åˆ†ä½
SYNERGY_D2_THRESHOLD = 0.75  # D2 (å†…å¤–å°é”) é˜ˆå€¼ï¼Œçº¦ 75th ç™¾åˆ†ä½
SYNERGY_FACTOR = 0.5  # ååŒå› å­ (å‰Šå¼±ç‰ˆ: é¡¶çº§+8~12åˆ†, JJJç±»+4~6åˆ†)


def sigmoid_availability(games, g0=SIGMOID_G0, k=SIGMOID_K):
    """è®¡ç®—å¯ç”¨æ€§å› å­ (Sigmoid å‡½æ•°)ã€‚

    - ä½äº g0: å¿«é€Ÿæ¥è¿‘ 0 (æ·˜æ±°ä½å‡ºåœºçƒå‘˜)
    - ç­‰äº g0: è¿”å› 0.5 (åŠæ ¼çº¿)
    - é«˜äº g0: é€æ¸æ¥è¿‘ 1.0 (è¾¹é™…æ•ˆç”¨é€’å‡ï¼Œé˜²æ­¢é“äººåˆ·åˆ†)

    Args:
        games: å‡ºåœºåœºæ¬¡
        g0: Sigmoid ä¸­ç‚¹ (é»˜è®¤ 45 åœº)
        k: æ–œç‡å› å­ (é»˜è®¤ 0.15)

    Returns:
        å¯ç”¨æ€§å› å­ (0-1)
    """
    return 1.0 / (1.0 + np.exp(-k * (games - g0)))


# =============================================================================
# è§’è‰²ç›¸å…³æ€§ç³»æ•° (Role Relevance Coefficient)
# Guards: çº¯ "G" (ä¸å« F æˆ– C)
# Frontcourt: å« "F" æˆ– "C" (åŒ…æ‹¬ G-F, F-G, F, F-C, C-F, C)
# =============================================================================
ROLE_CONFIG = {
    "Guards": {
        "D2_EXT_WEIGHT": 0.65,  # å¤–çº¿ (ä¸‰åˆ†é˜²å®ˆ) æƒé‡
        "D2_INT_WEIGHT": 0.35,  # å†…çº¿ (æŠ¤ç­) æƒé‡
        "D5_IMPACT": 0.4,  # ç¯®æ¿æƒé‡è¡°å‡ç³»æ•°
    },
    "Frontcourt": {
        "D2_EXT_WEIGHT": 0.45,  # å¤–çº¿ (ä¸‰åˆ†é˜²å®ˆ) æƒé‡
        "D2_INT_WEIGHT": 0.55,  # å†…çº¿ (æŠ¤ç­) æƒé‡
        "D5_IMPACT": 1.0,  # ç¯®æ¿æƒé‡å®Œæ•´ä¿ç•™
    },
}


def classify_role(position):
    """
    æ ¹æ®ä½ç½®åˆ†ç±»çƒå‘˜è§’è‰²
    Guards: çº¯ G (ä¸å« F æˆ– C)
    Frontcourt: å…¶ä»–æ‰€æœ‰ (å« F æˆ– C)
    """
    if pd.isna(position) or position == "":
        return "Frontcourt"  # é»˜è®¤å‰åœº
    pos = str(position).upper()
    # åªæœ‰çº¯ G æ‰ç®— Guardsï¼Œå…¶ä»–éƒ½ç®— Frontcourt
    if "F" in pos or "C" in pos:
        return "Frontcourt"
    if "G" in pos:
        return "Guards"
    return "Frontcourt"  # é»˜è®¤å‰åœº


def get_league_data(endpoint_func, **kwargs):
    """Helper to fetch data with retry logic"""
    try:
        # CommonTeamRoster doesn't accept 'season_type_all_star'
        if (
            "CommonTeamRoster" in endpoint_func.__name__
            or "CommonAllPlayers" in endpoint_func.__name__
        ):
            params = {
                "season": SEASON,
                "timeout": 60,
                **kwargs,
            }
        else:
            params = {
                "season": SEASON,
                "season_type_all_star": "Regular Season",
                "timeout": 60,
                **kwargs,
            }

        resp = endpoint_func(**params)
        df = resp.get_data_frames()[0]
        time.sleep(0.6)  # Reduced from 1.2 to speed up loop
        return df
    except Exception as e:
        print(f"  ERROR fetching {endpoint_func.__name__}: {e}")
        return pd.DataFrame()


def standardize_pt_defend_columns(df, fg_pct_col="D_FG_PCT", fga_col="D_FGA"):
    """
    Fix column names for LeagueDashPtDefend.
    Different categories have different column names for FG% and FGA:
    - Overall: D_FG_PCT, D_FGA
    - Less Than 6Ft: LT_06_PCT, LT_06_FGA (Often just FGA or D_FGA)
    - 3 Pointers: FG3_PCT, FG3A
    """
    if df.empty:
        return df

    # Rename PLAYER_ID
    if "CLOSE_DEF_PERSON_ID" in df.columns:
        df = df.rename(columns={"CLOSE_DEF_PERSON_ID": "PLAYER_ID"})

    # Rename FG% column to standard name
    if fg_pct_col in df.columns and fg_pct_col != "D_FG_PCT":
        df = df.rename(columns={fg_pct_col: "D_FG_PCT"})

    potential_fga_cols = ["D_FGA", "FGA", "FG3A", "FGA_LT_06", "LT_06_FGA"]
    found_col = None
    for col in potential_fga_cols:
        if col in df.columns:
            found_col = col
            break

    if found_col:
        if found_col != fga_col:
            df = df.rename(columns={found_col: fga_col})

    if "D_FGA" in df.columns and fga_col != "D_FGA":
        df = df.rename(columns={"D_FGA": fga_col})

    if "FGA" in df.columns and fga_col != "FGA":
        df = df.rename(columns={"FGA": fga_col})

    if "FG3A" in df.columns and fga_col != "FG3A":
        df = df.rename(columns={"FG3A": fga_col})

    return df


def bayesian_score(raw_pct, n, c=BAYES_C):
    """
    è´å¶æ–¯æ”¶ç¼©å…¬å¼
    raw_pct: åŸå§‹ç™¾åˆ†ä½ (0-1)
    n: æ ·æœ¬é‡
    c: æ”¶ç¼©å¸¸æ•°
    è¿”å›: æ”¶ç¼©åçš„åˆ†æ•°, ç½®ä¿¡åº¦æƒé‡
    """
    score = (n * raw_pct + c * 0.5) / (n + c)
    weight = n / (n + c)
    return score, weight


def analyze_season(target_season):
    print(f"\n=== Analyzing Season: {target_season} ===")

    # =============================================================================
    # STEP 1: FETCH DATA
    # =============================================================================

    print("1. Fetching D1: Shot Suppression (Overall)...")
    d1_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="Overall",
    )
    d1_df = standardize_pt_defend_columns(d1_df, fg_pct_col="D_FG_PCT", fga_col="D_FGA")
    print(f"   -> {len(d1_df)} players")

    print("2. Fetching D2: Shot Profile (Rim - Less Than 6Ft)...")
    d2_rim_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="Less Than 6Ft",
    )
    # FIX: Column is 'LT_06_PCT' not 'D_FG_PCT'
    d2_rim_df = standardize_pt_defend_columns(
        d2_rim_df, fg_pct_col="LT_06_PCT", fga_col="LT_06_FGA"
    )
    print(f"   -> {len(d2_rim_df)} players")

    print("3. Fetching D2: Shot Profile (3PT)...")
    d2_3pt_df = get_league_data(
        leaguedashptdefend.LeagueDashPtDefend,
        season=target_season,
        defense_category="3 Pointers",
    )
    # FIX: Column is 'FG3_PCT' not 'D_FG_PCT'
    d2_3pt_df = standardize_pt_defend_columns(
        d2_3pt_df, fg_pct_col="FG3_PCT", fga_col="FG3A"
    )
    print(f"   -> {len(d2_3pt_df)} players")

    print("4. Fetching D3: Hustle Stats...")
    d3_df = get_league_data(
        leaguehustlestatsplayer.LeagueHustleStatsPlayer,
        season=target_season,
        per_mode_time="PerGame",
    )
    print(f"   -> {len(d3_df)} players")

    print("5. Fetching D4: Player Stats (STL, BLK, PF)...")
    d4_df = get_league_data(
        leaguedashplayerstats.LeagueDashPlayerStats,
        season=target_season,
        per_mode_detailed="PerGame",
    )
    print(f"   -> {len(d4_df)} players")

    print("6. Fetching D5: Advanced Stats (DREB_PCT)...")
    d5_adv_df = get_league_data(
        leaguedashplayerstats.LeagueDashPlayerStats,
        season=target_season,
        per_mode_detailed="PerGame",
        measure_type_detailed_defense="Advanced",
    )
    print(f"   -> {len(d5_adv_df)} players")

    # Fetch LeagueSeasonMatchups for Matchup Difficulty calculation
    print("7. Fetching LeagueSeasonMatchups for Matchup Difficulty...")
    matchup_df = pd.DataFrame()
    try:
        matchup_resp = leagueseasonmatchups.LeagueSeasonMatchups(
            season=target_season,
            season_type_playoffs="Regular Season",
            per_mode_simple="Totals",
            timeout=120,
        )
        matchup_df = matchup_resp.get_data_frames()[0]
        print(f"   -> {len(matchup_df)} matchup records")
        time.sleep(0.6)
    except Exception as e:
        print(f"   WARNING: Could not fetch matchups: {e}")

    # =============================================================================
    # STEP 2: DATA PROCESSING
    # =============================================================================
    print("\nProcessing Data...")

    if d4_df.empty:
        print("CRITICAL ERROR: Failed to fetch base player stats. Exiting.")
        return pd.DataFrame()

    # Base DataFrame with eligible players

    # åŠ¨æ€è®¡ç®— MIN_GPï¼šå½“å‰èµ›å­£æœ€å¤§æ¯”èµ›åœºæ¬¡çš„ä¸€åŠ
    MAX_GP = d4_df["GP"].max()
    MIN_GP = MAX_GP // 2
    print(f"\n   å½“å‰èµ›å­£æœ€å¤§æ¯”èµ›åœºæ¬¡: {MAX_GP}, å…¥å›´é—¨æ§›: GP >= {MIN_GP}")

    base_df = d4_df[(d4_df["GP"] >= MIN_GP) & (d4_df["MIN"] >= MIN_MIN)].copy()[
        ["PLAYER_ID", "PLAYER_NAME", "GP", "MIN", "PF", "STL", "BLK"]
    ]

    # Fetch Position Data
    print("7. Fetching Player Positions...")
    try:
        # Use commonteamroster iterated over teams as fallback if biostats fails or returns incomplete data
        # But first try biostats as it was in original code (commented out but then imported)

        # Original code used leaguedashplayerbiostats at line 336
        bio_df = get_league_data(
            leaguedashplayerbiostats.LeagueDashPlayerBioStats, season=target_season
        )

        # Original code also had a fallback using commonteamroster
        nba_teams = teams.get_teams()
        all_rosters = []

        print("   Fetching rosters for position data (30 teams)...")
        for t in nba_teams:
            try:
                roster = get_league_data(
                    commonteamroster.CommonTeamRoster,
                    season=target_season,
                    team_id=t["id"],
                )
                if not roster.empty:
                    all_rosters.append(roster[["PLAYER_ID", "POSITION"]])
            except:
                pass

        if all_rosters:
            roster_df = pd.concat(all_rosters)
            # Merge position
            base_df = base_df.merge(roster_df, on="PLAYER_ID", how="left")
            base_df["PLAYER_POSITION"] = base_df["POSITION"]  # Unify column name
        else:
            base_df["PLAYER_POSITION"] = "Unknown"

    except Exception as e:
        print(f"   WARNING: Could not fetch positions: {e}")
        base_df["PLAYER_POSITION"] = "Unknown"

    # Merge DREB_PCT from advanced stats
    if not d5_adv_df.empty and "DREB_PCT" in d5_adv_df.columns:
        adv_cols = d5_adv_df[["PLAYER_ID", "DREB_PCT"]]
        base_df = base_df.merge(adv_cols, on="PLAYER_ID", how="left")
        print("   D5 Advanced data merged: OK")
    else:
        print("   WARNING: DREB_PCT data missing, using fallback")
        base_df["DREB_PCT"] = np.nan

    print(f"   -> {len(base_df)} eligible players (GP>={MIN_GP}, MIN>={MIN_MIN})")

    # =============================================================================
    # D1-D5 åˆ†æ•°è®¡ç®— (è´å¶æ–¯æ”¶ç¼©) + æƒé‡ w_k (è´å¶æ–¯ç½®ä¿¡åº¦)
    # =============================================================================

    C = BAYES_C

    # --- D4: Defensive IQ (é˜²å®ˆçƒå•†) ---
    base_df["Stocks"] = base_df["STL"] + base_df["BLK"]
    base_df["D4_Ratio"] = base_df["Stocks"] / (base_df["PF"] + 1)
    base_df["D4_Raw"] = base_df["D4_Ratio"].rank(pct=True)  # åŸå§‹ç™¾åˆ†ä½
    base_df["D4_N"] = base_df["MIN"] * base_df["GP"]  # æ ·æœ¬é‡ = æ€»ä¸Šåœºåˆ†é’Ÿæ•°
    d4_result = base_df.apply(lambda r: bayesian_score(r["D4_Raw"], r["D4_N"]), axis=1)
    base_df["D4_Score"] = d4_result.apply(lambda x: x[0])
    base_df["W4"] = d4_result.apply(lambda x: x[1])
    print("   D4 (Defensive IQ): OK")

    # =============================================================================
    # Matchup Difficulty (MD) Calculation
    # =============================================================================
    print("   Calculating Matchup Difficulty (MD)...")
    md_df = pd.DataFrame()

    if not matchup_df.empty:
        # Step 1: Calculate each offensive player's scoring ability
        off_agg = (
            matchup_df.groupby("OFF_PLAYER_ID")
            .agg({"PLAYER_PTS": "sum", "PARTIAL_POSS": "sum"})
            .reset_index()
        )
        off_agg = off_agg[off_agg["PARTIAL_POSS"] >= 50]  # Min 50 possessions
        off_agg["OFF_PTS_PER_100"] = (
            off_agg["PLAYER_PTS"] / off_agg["PARTIAL_POSS"]
        ) * 100
        off_ability = off_agg.set_index("OFF_PLAYER_ID")["OFF_PTS_PER_100"].to_dict()

        # Step 2: Calculate each defender's Matchup Difficulty
        def calc_defender_md(group):
            total_poss = 0
            weighted_sum = 0
            for _, row in group.iterrows():
                off_id = row["OFF_PLAYER_ID"]
                poss = row["PARTIAL_POSS"]
                if off_id in off_ability and poss > 0:
                    weighted_sum += off_ability[off_id] * poss
                    total_poss += poss
            if total_poss >= 50:  # Min 50 possessions defended
                return weighted_sum / total_poss
            return np.nan

        def_groups = matchup_df.groupby("DEF_PLAYER_ID")
        md_values = def_groups.apply(calc_defender_md)
        md_df = pd.DataFrame(
            {"PLAYER_ID": md_values.index, "MATCHUP_DIFFICULTY": md_values.values}
        )
        md_df = md_df.dropna()

        # Calculate MD percentile and Z-score for adjustment
        md_mean = md_df["MATCHUP_DIFFICULTY"].mean()
        md_std = md_df["MATCHUP_DIFFICULTY"].std()
        md_df["MD_Zscore"] = (md_df["MATCHUP_DIFFICULTY"] - md_mean) / md_std
        md_df["MD_Percentile"] = md_df["MATCHUP_DIFFICULTY"].rank(pct=True)

        print(f"   -> MD calculated for {len(md_df)} defenders")
        print(f"   -> League avg MD: {md_mean:.2f}, Std: {md_std:.2f}")
    else:
        print("   WARNING: No matchup data available for MD calculation")
        # Define defaults for missing MD
        md_mean = 24.0

    # Merge MD into base_df
    if not md_df.empty:
        base_df = base_df.merge(
            md_df[["PLAYER_ID", "MATCHUP_DIFFICULTY", "MD_Zscore", "MD_Percentile"]],
            on="PLAYER_ID",
            how="left",
        )
        # Fill missing MD with league average (neutral adjustment)
        base_df["MD_Zscore"] = base_df["MD_Zscore"].fillna(0)
        base_df["MD_Percentile"] = base_df["MD_Percentile"].fillna(0.5)
        base_df["MATCHUP_DIFFICULTY"] = base_df["MATCHUP_DIFFICULTY"].fillna(
            md_mean if not md_df.empty else 24.0
        )
        print("   MD merged into base_df: OK")
    else:
        base_df["MD_Zscore"] = 0
        base_df["MD_Percentile"] = 0.5
        base_df["MATCHUP_DIFFICULTY"] = 24.0  # Default league average
        print("   WARNING: MD data unavailable, using default values")

    # --- D1: Shot Suppression (Value Added + Matchup Difficulty Adjustment) ---
    if not d1_df.empty and "D_FG_PCT" in d1_df.columns and "PLAYER_ID" in d1_df.columns:
        d1_min = d1_df[
            ["PLAYER_ID", "D_FG_PCT", "D_FGA", "PCT_PLUSMINUS", "NORMAL_FG_PCT"]
        ]
        base_df = base_df.merge(d1_min, on="PLAYER_ID", how="left")
        base_df.loc[base_df["D_FGA"] < 5, "D_FG_PCT"] = np.nan
        base_df.loc[base_df["D_FGA"] < 5, "PCT_PLUSMINUS"] = np.nan

        # MD adjustment: subtract expected impact from PLUSMINUS
        # Higher MD (defending better scorers) allows higher PLUSMINUS
        # Each +1 std MD allows +1.5% higher opponent FG%
        MD_K = 0.018  # MD adjustment coefficient (1.8% per std)
        base_df["PCT_PLUSMINUS_ADJ"] = base_df["PCT_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )

        # Use adjusted PCT_PLUSMINUS for ranking
        base_df["D1_Raw"] = 1 - base_df["PCT_PLUSMINUS_ADJ"].rank(pct=True)
        base_df["D1_N"] = base_df["D_FGA"].fillna(0) * base_df["GP"]  # æ ·æœ¬é‡

        d1_result = base_df.apply(
            lambda r: bayesian_score(
                r["D1_Raw"] if pd.notna(r["D1_Raw"]) else 0.5, r["D1_N"]
            ),
            axis=1,
        )
        base_df["D1_Score"] = d1_result.apply(lambda x: x[0])
        base_df["W1"] = d1_result.apply(lambda x: x[1])
        print("   D1 (Suppression - Value Added + MD Adjustment): OK")
    else:
        print("   WARNING: D1 data missing")
        base_df["D1_Score"] = 0.5
        base_df["W1"] = 0.0

    # --- D2: Shot Profile (Rim + 3PT) - Value Added + MD Adjustment ---
    # MD adjustment: subtract expected impact (same logic as D1)
    MD_K = 0.015  # MD adjustment coefficient (1.5% per std)

    # Rim (æŠ¤ç­) - ä½¿ç”¨ PLUSMINUS + MDè°ƒæ•´
    if (
        not d2_rim_df.empty
        and "D_FG_PCT" in d2_rim_df.columns
        and "PLAYER_ID" in d2_rim_df.columns
    ):
        d2_rim = d2_rim_df[["PLAYER_ID", "D_FG_PCT", "LT_06_FGA", "PLUSMINUS"]].rename(
            columns={
                "D_FG_PCT": "Rim_DFG",
                "LT_06_FGA": "Rim_FGA",
                "PLUSMINUS": "Rim_PLUSMINUS",
            }
        )
        base_df = base_df.merge(d2_rim, on="PLAYER_ID", how="left")
        # MD Adjustment for Rim: subtract expected impact
        base_df["Rim_PLUSMINUS_ADJ"] = base_df["Rim_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )
        # Value Added: PLUSMINUS è¶Šè´Ÿè¶Šå¥½ (ä½¿ç”¨è°ƒæ•´åçš„å€¼)
        base_df["Rim_Raw"] = 1 - base_df["Rim_PLUSMINUS_ADJ"].rank(pct=True)
        print("   D2 (Rim - Value Added + MD): OK")
    else:
        print(
            "   WARNING: D2 Rim data missing - columns:",
            d2_rim_df.columns.tolist() if not d2_rim_df.empty else "EMPTY",
        )
        base_df["Rim_Raw"] = 0.5
        base_df["Rim_FGA"] = 0
        base_df["Rim_PLUSMINUS"] = np.nan
        base_df["Rim_PLUSMINUS_ADJ"] = np.nan

    # 3PT (ä¸‰åˆ†) - ä½¿ç”¨ PLUSMINUS + MDè°ƒæ•´
    if (
        not d2_3pt_df.empty
        and "D_FG_PCT" in d2_3pt_df.columns
        and "PLAYER_ID" in d2_3pt_df.columns
    ):
        d2_3pt = d2_3pt_df[["PLAYER_ID", "D_FG_PCT", "FG3A", "PLUSMINUS"]].rename(
            columns={
                "D_FG_PCT": "3PT_DFG",
                "FG3A": "FG3_FGA",
                "PLUSMINUS": "3PT_PLUSMINUS",
            }
        )
        base_df = base_df.merge(d2_3pt, on="PLAYER_ID", how="left")
        # MD Adjustment for 3PT: subtract expected impact
        base_df["3PT_PLUSMINUS_ADJ"] = base_df["3PT_PLUSMINUS"] - (
            MD_K * base_df["MD_Zscore"]
        )
        # Value Added: PLUSMINUS è¶Šè´Ÿè¶Šå¥½ (ä½¿ç”¨è°ƒæ•´åçš„å€¼)
        base_df["3PT_Raw"] = 1 - base_df["3PT_PLUSMINUS_ADJ"].rank(pct=True)
        print("   D2 (3PT - Value Added + MD): OK")
    else:
        print(
            "   WARNING: D2 3PT data missing - columns:",
            d2_3pt_df.columns.tolist() if not d2_3pt_df.empty else "EMPTY",
        )
        base_df["3PT_Raw"] = 0.5
        base_df["FG3_FGA"] = 0
        base_df["3PT_PLUSMINUS"] = np.nan
        base_df["3PT_PLUSMINUS_ADJ"] = np.nan

    # Combined D2: åŸºäºè§’è‰²çš„å†…å¤–çº¿æƒé‡
    rim_raw = base_df["Rim_Raw"].fillna(0.5)
    pt3_raw = base_df["3PT_Raw"].fillna(0.5)

    # æ·»åŠ è§’è‰²åˆ†ç±»
    base_df["ROLE"] = base_df["PLAYER_POSITION"].apply(classify_role)

    # --- è®¡ç®— Roamer_Index å’Œ Roamer_Pct (ç”¨äº D2 å’Œ D5 æƒé‡è°ƒæ•´) ---
    # Roamer_Index = BLK_per_36 / (DREB_PCT + 0.01)
    # é«˜å€¼ = æ‰«è¡å‹å†…çº¿ (ç›–å¸½å¤šï¼Œç¯®æ¿å°‘)
    base_df["BLK_per_36"] = base_df["BLK"] / base_df["MIN"] * 36
    base_df["Roamer_Index"] = base_df["BLK_per_36"] / (base_df["DREB_PCT"] + 0.01)

    # ä»…å¯¹ Frontcourt çƒå‘˜è®¡ç®—ç™¾åˆ†ä½æ’å
    frontcourt_mask = base_df["ROLE"] == "Frontcourt"
    base_df.loc[frontcourt_mask, "Roamer_Pct"] = base_df.loc[
        frontcourt_mask, "Roamer_Index"
    ].rank(pct=True)
    base_df["Roamer_Pct"] = base_df["Roamer_Pct"].fillna(0)  # Guards ä¸å—å½±å“

    def calc_d2_raw(row):
        role = row["ROLE"]
        config = ROLE_CONFIG[role]
        base_int = config["D2_INT_WEIGHT"]
        base_ext = config["D2_EXT_WEIGHT"]

        # Roamer åŠ¨æ€å¤–çº¿æƒé‡è°ƒæ•´ (ä»… Frontcourt)
        # adjusted_ext = base_ext * (1 - D2_EXT_ROAMER_K * Roamer_Pct)
        roamer_pct = row.get("Roamer_Pct", 0) if role == "Frontcourt" else 0
        adjusted_ext = base_ext * (1 - D2_EXT_ROAMER_K * roamer_pct)
        adjusted_int = 1 - adjusted_ext

        return (rim_raw[row.name] * adjusted_int) + (pt3_raw[row.name] * adjusted_ext)

    base_df["D2_Raw"] = base_df.apply(calc_d2_raw, axis=1)

    # æ ·æœ¬é‡ = æŠ¤ç­é˜²å®ˆæ¬¡æ•° + ä¸‰åˆ†é˜²å®ˆæ¬¡æ•° (åŸºäºè§’è‰²åŠ æƒï¼Œå« Roamer è°ƒæ•´)
    rim_fga = base_df["Rim_FGA"].fillna(0) * base_df["GP"]
    fg3_fga = base_df["FG3_FGA"].fillna(0) * base_df["GP"]

    def calc_d2_n(row):
        role = row["ROLE"]
        config = ROLE_CONFIG[role]
        base_int = config["D2_INT_WEIGHT"]
        base_ext = config["D2_EXT_WEIGHT"]

        # Roamer åŠ¨æ€å¤–çº¿æƒé‡è°ƒæ•´ (ä¸ D2_Raw ä¸€è‡´)
        roamer_pct = row.get("Roamer_Pct", 0) if role == "Frontcourt" else 0
        adjusted_ext = base_ext * (1 - D2_EXT_ROAMER_K * roamer_pct)
        adjusted_int = 1 - adjusted_ext

        return (rim_fga[row.name] * adjusted_int) + (fg3_fga[row.name] * adjusted_ext)

    base_df["D2_N"] = base_df.apply(calc_d2_n, axis=1)
    print("   D2 (Zone Defense - Roamer-adjusted): OK")

    d2_result = base_df.apply(lambda r: bayesian_score(r["D2_Raw"], r["D2_N"]), axis=1)
    base_df["D2_Score"] = d2_result.apply(lambda x: x[0])
    base_df["W2"] = d2_result.apply(lambda x: x[1])

    # --- D3: Hustle Index ---
    if not d3_df.empty:
        hustle_cols = d3_df[
            ["PLAYER_ID", "DEFLECTIONS", "CHARGES_DRAWN", "CONTESTED_SHOTS"]
        ]
        base_df = base_df.merge(hustle_cols, on="PLAYER_ID", how="left")

        defl = base_df["DEFLECTIONS"].fillna(0)
        chrg = base_df["CHARGES_DRAWN"].fillna(0)
        cont = base_df["CONTESTED_SHOTS"].fillna(0)

        base_df["Z_Defl"] = stats.zscore(defl)
        base_df["Z_Chrg"] = stats.zscore(chrg)
        base_df["Z_Cont"] = stats.zscore(cont)

        base_df["Hustle_Raw"] = (
            base_df["Z_Defl"] + (base_df["Z_Chrg"] * 2) + base_df["Z_Cont"]
        )
        base_df["D3_Raw"] = base_df["Hustle_Raw"].rank(pct=True)
        base_df["D3_N"] = base_df["MIN"] * base_df["GP"]

        d3_result = base_df.apply(
            lambda r: bayesian_score(r["D3_Raw"], r["D3_N"]), axis=1
        )
        base_df["D3_Score"] = d3_result.apply(lambda x: x[0])
        base_df["W3"] = d3_result.apply(lambda x: x[1])
        print("   D3 (Hustle): OK")
    else:
        print("   WARNING: D3 Hustle data missing")
        base_df["D3_Score"] = 0.5
        base_df["W3"] = 0.0

    # --- D5: Anchor / Rebound Protection (ç¯®æ¿ä¿æŠ¤) ---
    base_df["D5_Raw"] = base_df["DREB_PCT"].rank(pct=True)
    base_df["D5_N"] = base_df["MIN"] * base_df["GP"]

    d5_result = base_df.apply(
        lambda r: bayesian_score(
            r["D5_Raw"] if pd.notna(r["D5_Raw"]) else 0.5, r["D5_N"]
        ),
        axis=1,
    )
    base_df["D5_Score"] = d5_result.apply(lambda x: x[0])
    base_df["W5_Base"] = d5_result.apply(lambda x: x[1])

    # åº”ç”¨è§’è‰²ç›¸å…³æ€§ç³»æ•° (Role Relevance Coefficient)
    base_df["W5"] = base_df.apply(
        lambda r: r["W5_Base"] * ROLE_CONFIG[r["ROLE"]]["D5_IMPACT"], axis=1
    )

    # --- Roamer åŠ¨æ€ D5 æƒé‡è°ƒèŠ‚ ---
    # Roamer_Pct å·²åœ¨ D2 è®¡ç®—å‰è®¡ç®—å®Œæˆ
    # åº”ç”¨åŠ¨æ€è°ƒæ•´: W5 = W5 * (1 - ROAMER_K * Roamer_Pct)
    # å…ˆä¿å­˜è°ƒæ•´å‰çš„ W5 ç”¨äºè®¡ç®—æƒé‡æŸå¤±
    base_df["W5_Before_Roamer"] = base_df["W5"].copy()
    base_df["W5"] = base_df["W5"] * (1 - ROAMER_K * base_df["Roamer_Pct"])

    # --- Roamer æƒé‡é‡åˆ†é… (Weight Redistribution) ---
    # å°† Roamer çƒå‘˜å›  D5 é™æƒè€Œå¤±å»çš„æƒé‡ï¼Œé‡æ–°åˆ†é…åˆ°äº§å‡ºå±‚å’Œæ´»åŠ›å±‚
    # è¿™ä½“ç°äº†"èŒè´£åˆ†å·¥"çš„å…¬å¹³æ€§ï¼šæ‰«è¡è€…ç‰ºç‰²ç¯®æ¿æ¢å–åé˜²ï¼Œåº”è·å¾—ç›¸åº”è¡¥å¿
    base_df["W5_Lost"] = base_df["W5_Before_Roamer"] - base_df["W5"]

    # åˆ†é…ç»™äº§å‡ºå±‚ (W1/W2): æŒ‰ W1:W2 çš„åŸæœ‰æ¯”ä¾‹åˆ†é…
    w1_w2_total = base_df["W1"] + base_df["W2"] + 1e-6
    base_df["W1"] = base_df["W1"] + base_df["W5_Lost"] * ROAMER_WEIGHT_REDIST_OUTPUT * (
        base_df["W1"] / w1_w2_total
    )
    base_df["W2"] = base_df["W2"] + base_df["W5_Lost"] * ROAMER_WEIGHT_REDIST_OUTPUT * (
        base_df["W2"] / w1_w2_total
    )

    # åˆ†é…ç»™æ´»åŠ›å±‚ (W3): å…¨éƒ¨åˆ†é…ç»™ D3
    base_df["W3"] = base_df["W3"] + base_df["W5_Lost"] * ROAMER_WEIGHT_REDIST_HUSTLE

    # æ‰“å°æƒé‡é‡åˆ†é…ç»Ÿè®¡
    roamer_beneficiaries = (base_df["W5_Lost"] > 0.05).sum()
    if roamer_beneficiaries > 0:
        print(f"   Roamer æƒé‡é‡åˆ†é…: {roamer_beneficiaries} åçƒå‘˜å—ç›Š")
        top_beneficiaries = base_df.nlargest(3, "W5_Lost")[["PLAYER_NAME", "W5_Lost"]]
        for _, row in top_beneficiaries.iterrows():
            print(
                f"      {row['PLAYER_NAME']}: W5 æŸå¤± {row['W5_Lost']:.3f} -> é‡åˆ†é…åˆ° W1/W2/W3"
            )

    print(
        "   D5 (Anchor/DREB%): OK (Role-adjusted, Roamer-corrected, Weight-redistributed)"
    )

    # =============================================================================
    # æ•ˆç‡æ¨¡å‹æ¡†æ¶ (Efficiency Model Framework)
    # =============================================================================

    # Fill NaN scores with 0.5 (neutral)
    score_cols = ["D1_Score", "D2_Score", "D3_Score", "D4_Score", "D5_Score"]
    weight_cols = ["W1", "W2", "W3", "W4", "W5"]

    for col in score_cols:
        base_df[col] = base_df[col].fillna(0.5)

    for col in weight_cols:
        base_df[col] = base_df[col].fillna(0)

    # Step 1: è®¡ç®—å®é™…äº§å‡º (D1 + D2 çš„åŠ æƒå¹³å‡)
    base_df["Actual_Output"] = (
        base_df["D1_Score"] * base_df["W1"] + base_df["D2_Score"] * base_df["W2"]
    ) / (base_df["W1"] + base_df["W2"] + 1e-6)

    # Step 2: è®¡ç®—æŠ•å…¥åˆ† (D3 + D4 çš„åŠ æƒå¹³å‡)
    base_df["Input_Score"] = (
        base_df["D3_Score"] * base_df["W3"] + base_df["D4_Score"] * base_df["W4"]
    ) / (base_df["W3"] + base_df["W4"] + 1e-6)

    # Step 3: ç”¨çº¿æ€§å›å½’å»ºç«‹ æŠ•å…¥ â†’ é¢„æœŸäº§å‡º çš„æ¨¡å‹
    valid_mask = (
        (base_df["W1"] > 0.1)
        & (base_df["W2"] > 0.1)
        & (base_df["W3"] > 0.1)
        & (base_df["W4"] > 0.1)
    )
    if valid_mask.sum() > 10:
        X_train = base_df.loc[valid_mask, "Input_Score"].values.reshape(-1, 1)
        y_train = base_df.loc[valid_mask, "Actual_Output"].values

        reg_model = LinearRegression()
        reg_model.fit(X_train, y_train)

        # é¢„æµ‹æ‰€æœ‰çƒå‘˜çš„é¢„æœŸäº§å‡º
        base_df["Expected_Output"] = reg_model.predict(
            base_df["Input_Score"].values.reshape(-1, 1)
        )

        print(
            f"   å›å½’æ¨¡å‹: Expected_Output = {reg_model.intercept_:.4f} + {reg_model.coef_[0]:.4f} * Input_Score"
        )
        print(f"   RÂ² = {reg_model.score(X_train, y_train):.4f}")
    else:
        print(
            "   WARNING: Not enough valid data for regression model. Using Actual as Expected."
        )
        base_df["Expected_Output"] = base_df["Actual_Output"]
        # Dummy model for Hansen logic
        reg_model = LinearRegression()
        reg_model.intercept_ = 0
        reg_model.coef_ = np.array([1.0])

    # Step 4: è®¡ç®—æ•ˆç‡ç³»æ•°
    base_df["Efficiency"] = base_df["Actual_Output"] / (
        base_df["Expected_Output"] + 1e-6
    )
    base_df["Efficiency"] = base_df["Efficiency"].clip(0.5, 1.5)

    # Step 5: è®¡ç®—æ–°çš„ EDI
    output_weighted = (
        base_df["Actual_Output"]
        * base_df["Efficiency"]
        * (base_df["W1"] + base_df["W2"])
    )
    input_weighted = base_df["Input_Score"] * (base_df["W3"] + base_df["W4"])
    d5_weighted = base_df["D5_Score"] * base_df["W5"]

    total_weight = (
        base_df["W1"] + base_df["W2"] + base_df["W3"] + base_df["W4"] + base_df["W5"]
    )

    base_df["EDI_Total"] = np.where(
        total_weight > 0,
        (output_weighted + input_weighted + d5_weighted) / total_weight * 100,
        50.0,
    )

    # Step 6: åº”ç”¨ Sigmoid å¯ç”¨æ€§è°ƒæ•´
    # å…¬å¼: EDI_Final = EDI_Raw * Sigmoid(GP)
    # è¿™ä¼šæƒ©ç½šä½å‡ºåœºçƒå‘˜ï¼ŒåŒæ—¶é˜²æ­¢é“äººåˆ·åˆ† (è¾¹é™…æ•ˆç”¨é€’å‡)
    base_df["Sigmoid_Factor"] = base_df["GP"].apply(sigmoid_availability)
    base_df["EDI_Total"] = base_df["EDI_Total"] * base_df["Sigmoid_Factor"]

    # Step 7: ååŒæ•ˆåº”åŠ åˆ† (Synergy Bonus for Switchable Defenders)
    # å¥–åŠ±åŒæ—¶å…·å¤‡é«˜ D1 (å¯¹ä½å‹åˆ¶) å’Œé«˜ D2 (å†…å¤–å°é”) çš„"æ¢é˜²å…¨èƒ½å‹"é˜²å®ˆè€…
    # å…¬å¼ (å¹³æ–¹æ ¹ç‰ˆ): sqrt((D1 - T1) * (D2 - T2)) * Factor * 100
    def calc_synergy_bonus(row):
        d1, d2 = row["D1_Score"], row["D2_Score"]
        if d1 >= SYNERGY_D1_THRESHOLD and d2 >= SYNERGY_D2_THRESHOLD:
            # å¹³æ–¹æ ¹å…¬å¼ï¼šå‰Šå³°å¡«è°·ï¼Œç¼“è§£é©¬å¤ªæ•ˆåº”
            raw_synergy = (d1 - SYNERGY_D1_THRESHOLD) * (d2 - SYNERGY_D2_THRESHOLD)
            return np.sqrt(raw_synergy) * SYNERGY_FACTOR * 100
        return 0.0

    base_df["Synergy_Bonus"] = base_df.apply(calc_synergy_bonus, axis=1)
    base_df["EDI_Total"] = base_df["EDI_Total"] + base_df["Synergy_Bonus"]

    synergy_count = (base_df["Synergy_Bonus"] > 0).sum()
    if synergy_count > 0:
        print(f"   ååŒæ•ˆåº”åŠ åˆ†: {synergy_count} åçƒå‘˜è·å¾—åŠ åˆ†")
        top_synergy = base_df.nlargest(3, "Synergy_Bonus")[
            ["PLAYER_NAME", "Synergy_Bonus"]
        ]
        for _, row in top_synergy.iterrows():
            print(f"      {row['PLAYER_NAME']}: +{row['Synergy_Bonus']:.2f}")

    # è®¡ç®—æ•ˆç‡æ®‹å·® (ç”¨äºåˆ†æ)
    base_df["Efficiency_Residual"] = (
        base_df["Actual_Output"] - base_df["Expected_Output"]
    )

    print("   æ•ˆç‡æ¨¡å‹è®¡ç®—å®Œæˆ:")
    print(
        f"   -> é«˜æ•ˆçƒå‘˜ (Efficiency > 1.1): {len(base_df[base_df['Efficiency'] > 1.1])}"
    )
    print(
        f"   -> ä½æ•ˆçƒå‘˜ (Efficiency < 0.9): {len(base_df[base_df['Efficiency'] < 0.9])}"
    )

    print(
        f"\n   è§’è‰²åˆ†å¸ƒ: Guards={len(base_df[base_df['ROLE'] == 'Guards'])}, Frontcourt={len(base_df[base_df['ROLE'] == 'Frontcourt'])}"
    )

    # =============================================================================
    # 2025-26 èµ›å­£ç‰¹æ®Šå¤„ç†: ä¸º Hansen Yang å•ç‹¬è®¡ç®— EDI (å¿½ç•¥ GP é™åˆ¶)
    # =============================================================================
    if target_season == "2025-26":
        hansen_mask = d4_df["PLAYER_NAME"].str.contains("Hansen", case=False, na=False)
        if (
            hansen_mask.any()
            and not base_df["PLAYER_NAME"]
            .str.contains("Hansen", case=False, na=False)
            .any()
        ):
            print("\n   [ç‰¹æ®Šå¤„ç†] ä¸º Hansen Yang è®¡ç®— EDI (å¿½ç•¥ GP é™åˆ¶)...")

            # è·å– Hansen çš„åŸºç¡€æ•°æ®
            hansen_base = (
                d4_df[hansen_mask]
                .copy()[["PLAYER_ID", "PLAYER_NAME", "GP", "MIN", "PF", "STL", "BLK"]]
                .iloc[0:1]
            )

            # è·å–ä½ç½®ä¿¡æ¯
            hansen_id = hansen_base["PLAYER_ID"].values[0]
            hansen_base["PLAYER_POSITION"] = "F"  # å‰é”‹
            hansen_base["ROLE"] = "Frontcourt"

            # D4: Defensive IQ
            hansen_base["Stocks"] = hansen_base["STL"] + hansen_base["BLK"]
            hansen_base["D4_Ratio"] = hansen_base["Stocks"] / (hansen_base["PF"] + 1)
            # ä½¿ç”¨è”ç›Ÿæ’åè®¡ç®—ç™¾åˆ†ä½
            all_d4_ratios = d4_df["STL"] + d4_df["BLK"]
            all_d4_ratios = all_d4_ratios / (d4_df["PF"] + 1)
            hansen_d4_raw = (all_d4_ratios < hansen_base["D4_Ratio"].values[0]).mean()
            hansen_d4_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
            hansen_base["D4_Score"] = (hansen_d4_n * hansen_d4_raw + C * 0.5) / (
                hansen_d4_n + C
            )
            hansen_base["W4"] = hansen_d4_n / (hansen_d4_n + C)

            # D1: Shot Suppression (Value Added + MD Adjustment)
            if not d1_df.empty and hansen_id in d1_df["PLAYER_ID"].values:
                hansen_d1 = d1_df[d1_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_dfg = hansen_d1["D_FG_PCT"]
                hansen_dfga = hansen_d1["D_FGA"]
                hansen_pct_plusminus = hansen_d1["PCT_PLUSMINUS"]

                # Get Hansen's MD (if available)
                hansen_md_zscore = 0.0  # Default neutral
                if not md_df.empty and hansen_id in md_df["PLAYER_ID"].values:
                    hansen_md_row = md_df[md_df["PLAYER_ID"] == hansen_id].iloc[0]
                    hansen_md_zscore = hansen_md_row["MD_Zscore"]
                    hansen_base["MATCHUP_DIFFICULTY"] = hansen_md_row[
                        "MATCHUP_DIFFICULTY"
                    ]
                    hansen_base["MD_Zscore"] = hansen_md_zscore
                    hansen_base["MD_Percentile"] = hansen_md_row["MD_Percentile"]
                else:
                    hansen_base["MATCHUP_DIFFICULTY"] = 24.0
                    hansen_base["MD_Zscore"] = 0.0
                    hansen_base["MD_Percentile"] = 0.5

                # Apply MD adjustment: Adjusted_VA = PCT_PLUSMINUS * (1 + k * MD_Zscore)
                MD_K = 0.3
                hansen_pct_plusminus_adj = hansen_pct_plusminus * (
                    1 + MD_K * hansen_md_zscore
                )

                # Use adjusted PCT_PLUSMINUS to calculate percentile
                # Calculate adjusted VA for all players in d1_df for comparison
                if not md_df.empty:
                    d1_with_md = d1_df.merge(
                        md_df[["PLAYER_ID", "MD_Zscore"]], on="PLAYER_ID", how="left"
                    )
                    d1_with_md["MD_Zscore"] = d1_with_md["MD_Zscore"].fillna(0)
                    d1_with_md["PCT_PLUSMINUS_ADJ"] = d1_with_md["PCT_PLUSMINUS"] * (
                        1 + MD_K * d1_with_md["MD_Zscore"]
                    )
                    hansen_d1_raw = (
                        1
                        - (
                            d1_with_md["PCT_PLUSMINUS_ADJ"] < hansen_pct_plusminus_adj
                        ).mean()
                    )
                else:
                    hansen_d1_raw = (
                        1 - (d1_df["PCT_PLUSMINUS"] < hansen_pct_plusminus).mean()
                    )

                hansen_d1_n = hansen_dfga * hansen_base["GP"].values[0]
                hansen_base["D1_Score"] = (hansen_d1_n * hansen_d1_raw + C * 0.5) / (
                    hansen_d1_n + C
                )
                hansen_base["W1"] = hansen_d1_n / (hansen_d1_n + C)
                hansen_base["D_FG_PCT"] = hansen_dfg
                hansen_base["PCT_PLUSMINUS"] = hansen_pct_plusminus
                hansen_base["PCT_PLUSMINUS_ADJ"] = hansen_pct_plusminus_adj
            else:
                hansen_base["D1_Score"] = 0.5
                hansen_base["W1"] = 0.0
                hansen_base["D_FG_PCT"] = np.nan
                hansen_base["PCT_PLUSMINUS"] = np.nan
                hansen_base["PCT_PLUSMINUS_ADJ"] = np.nan
                hansen_base["MATCHUP_DIFFICULTY"] = 24.0
                hansen_base["MD_Zscore"] = 0.0
                hansen_base["MD_Percentile"] = 0.5

            # D2: Rim + 3PT (Frontcourt weights: å†…çº¿60% / å¤–çº¿40%) - Value Added
            hansen_rim_raw, hansen_3pt_raw = 0.5, 0.5
            hansen_rim_fga, hansen_3pt_fga = 0, 0

            if not d2_rim_df.empty and hansen_id in d2_rim_df["PLAYER_ID"].values:
                hansen_rim = d2_rim_df[d2_rim_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_rim_dfg = hansen_rim["D_FG_PCT"]
                hansen_rim_plusminus = hansen_rim["PLUSMINUS"]
                # Value Added: PLUSMINUS è¶Šè´Ÿè¶Šå¥½
                hansen_rim_raw = (
                    1 - (d2_rim_df["PLUSMINUS"] < hansen_rim_plusminus).mean()
                )
                hansen_rim_fga = hansen_rim.get("LT_06_FGA", 0)
                hansen_base["Rim_DFG"] = hansen_rim_dfg
                hansen_base["Rim_PLUSMINUS"] = hansen_rim_plusminus

            if not d2_3pt_df.empty and hansen_id in d2_3pt_df["PLAYER_ID"].values:
                hansen_3pt = d2_3pt_df[d2_3pt_df["PLAYER_ID"] == hansen_id].iloc[0]
                hansen_3pt_dfg = hansen_3pt["D_FG_PCT"]
                hansen_3pt_plusminus = hansen_3pt["PLUSMINUS"]
                # Value Added: PLUSMINUS è¶Šè´Ÿè¶Šå¥½
                hansen_3pt_raw = (
                    1 - (d2_3pt_df["PLUSMINUS"] < hansen_3pt_plusminus).mean()
                )
                hansen_3pt_fga = hansen_3pt.get("FG3A", 0)
                hansen_base["3PT_DFG"] = hansen_3pt_dfg
                hansen_base["3PT_PLUSMINUS"] = hansen_3pt_plusminus

            # Frontcourt: å†…çº¿60% / å¤–çº¿40%
            hansen_d2_raw = hansen_rim_raw * 0.6 + hansen_3pt_raw * 0.4
            hansen_d2_n = (hansen_rim_fga * 0.6 + hansen_3pt_fga * 0.4) * hansen_base[
                "GP"
            ].values[0]
            hansen_base["D2_Score"] = (hansen_d2_n * hansen_d2_raw + C * 0.5) / (
                hansen_d2_n + C
            )
            hansen_base["W2"] = hansen_d2_n / (hansen_d2_n + C)

            # D3: Hustle Index
            if not d3_df.empty and hansen_id in d3_df["PLAYER_ID"].values:
                hansen_d3 = d3_df[d3_df["PLAYER_ID"] == hansen_id].iloc[0]
                defl = hansen_d3.get("DEFLECTIONS", 0)
                chrg = hansen_d3.get("CHARGES_DRAWN", 0)
                cont = hansen_d3.get("CONTESTED_SHOTS", 0)

                # è®¡ç®— Z-score ç›¸å¯¹äºè”ç›Ÿ
                z_defl = (defl - d3_df["DEFLECTIONS"].mean()) / d3_df[
                    "DEFLECTIONS"
                ].std()
                z_chrg = (chrg - d3_df["CHARGES_DRAWN"].mean()) / d3_df[
                    "CHARGES_DRAWN"
                ].std()
                z_cont = (cont - d3_df["CONTESTED_SHOTS"].mean()) / d3_df[
                    "CONTESTED_SHOTS"
                ].std()
                hansen_hustle = z_defl + z_chrg * 2 + z_cont

                # è®¡ç®—ç™¾åˆ†ä½
                all_hustle = (
                    d3_df["DEFLECTIONS"] - d3_df["DEFLECTIONS"].mean()
                ) / d3_df["DEFLECTIONS"].std()
                all_hustle += (
                    (d3_df["CHARGES_DRAWN"] - d3_df["CHARGES_DRAWN"].mean())
                    / d3_df["CHARGES_DRAWN"].std()
                    * 2
                )
                all_hustle += (
                    d3_df["CONTESTED_SHOTS"] - d3_df["CONTESTED_SHOTS"].mean()
                ) / d3_df["CONTESTED_SHOTS"].std()
                hansen_d3_raw = (all_hustle < hansen_hustle).mean()
                hansen_d3_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
                hansen_base["D3_Score"] = (hansen_d3_n * hansen_d3_raw + C * 0.5) / (
                    hansen_d3_n + C
                )
                hansen_base["W3"] = hansen_d3_n / (hansen_d3_n + C)
                hansen_base["DEFLECTIONS"] = defl
            else:
                hansen_base["D3_Score"] = 0.5
                hansen_base["W3"] = 0.0

            # D5: DREB%
            if not d5_adv_df.empty and hansen_id in d5_adv_df["PLAYER_ID"].values:
                hansen_dreb = d5_adv_df[d5_adv_df["PLAYER_ID"] == hansen_id][
                    "DREB_PCT"
                ].values[0]
                hansen_d5_raw = (d5_adv_df["DREB_PCT"] < hansen_dreb).mean()
                hansen_d5_n = hansen_base["MIN"].values[0] * hansen_base["GP"].values[0]
                hansen_base["D5_Score"] = (hansen_d5_n * hansen_d5_raw + C * 0.5) / (
                    hansen_d5_n + C
                )
                hansen_base["W5"] = hansen_d5_n / (hansen_d5_n + C)  # Frontcourt: 1.0
                hansen_base["DREB_PCT"] = hansen_dreb
            else:
                hansen_base["D5_Score"] = 0.5
                hansen_base["W5"] = 0.0
                hansen_base["DREB_PCT"] = np.nan

            # è®¡ç®— EDI_Total (ä½¿ç”¨æ•ˆç‡æ¨¡å‹æ¡†æ¶)
            # Step 1: è®¡ç®—å®é™…äº§å‡º (Actual Output)
            hansen_w1 = hansen_base["W1"].values[0]
            hansen_w2 = hansen_base["W2"].values[0]
            hansen_w3 = hansen_base["W3"].values[0]
            hansen_w4 = hansen_base["W4"].values[0]
            hansen_w5 = hansen_base["W5"].values[0]

            hansen_d1 = hansen_base["D1_Score"].values[0]
            hansen_d2 = hansen_base["D2_Score"].values[0]
            hansen_d3 = hansen_base["D3_Score"].values[0]
            hansen_d4 = hansen_base["D4_Score"].values[0]
            hansen_d5 = hansen_base["D5_Score"].values[0]

            hansen_actual_output = (hansen_d1 * hansen_w1 + hansen_d2 * hansen_w2) / (
                hansen_w1 + hansen_w2 + 1e-6
            )
            hansen_base["Actual_Output"] = hansen_actual_output

            # Step 2: è®¡ç®—æŠ•å…¥åˆ† (Input Score)
            hansen_input_score = (hansen_d3 * hansen_w3 + hansen_d4 * hansen_w4) / (
                hansen_w3 + hansen_w4 + 1e-6
            )
            hansen_base["Input_Score"] = hansen_input_score

            # Step 3: ç”¨å·²æ‹Ÿåˆçš„å›å½’æ¨¡å‹é¢„æµ‹é¢„æœŸäº§å‡º
            if valid_mask.sum() > 10:
                hansen_expected_output = reg_model.predict([[hansen_input_score]])[0]
            else:
                hansen_expected_output = hansen_actual_output

            hansen_base["Expected_Output"] = hansen_expected_output

            # Step 4: è®¡ç®—æ•ˆç‡ç³»æ•° (é™åˆ¶åœ¨ [0.5, 1.5] èŒƒå›´)
            hansen_efficiency = hansen_actual_output / (hansen_expected_output + 1e-6)
            hansen_efficiency = np.clip(hansen_efficiency, 0.5, 1.5)
            hansen_base["Efficiency"] = hansen_efficiency

            # Step 5: è®¡ç®—æ•ˆç‡æ®‹å·®
            hansen_base["Efficiency_Residual"] = (
                hansen_actual_output - hansen_expected_output
            )

            # Step 6: è®¡ç®— EDI (ä½¿ç”¨æ•ˆç‡æ¨¡å‹å…¬å¼)
            output_weighted = (
                hansen_actual_output * hansen_efficiency * (hansen_w1 + hansen_w2)
            )
            input_weighted = hansen_input_score * (hansen_w3 + hansen_w4)
            d5_weighted = hansen_d5 * hansen_w5

            total_weight = hansen_w1 + hansen_w2 + hansen_w3 + hansen_w4 + hansen_w5
            hansen_base["EDI_Total"] = (
                (output_weighted + input_weighted + d5_weighted) / total_weight * 100
                if total_weight > 0
                else 50.0
            )

            print(
                f"   Hansen æ•ˆç‡æ¨¡å‹: Input={hansen_input_score:.3f}, Expected={hansen_expected_output:.3f}, Actual={hansen_actual_output:.3f}, Efficiency={hansen_efficiency:.3f}"
            )

            # æ·»åŠ åˆ° base_df
            base_df = pd.concat([base_df, hansen_base], ignore_index=True)
            print(
                f"   Hansen Yang EDI: {hansen_base['EDI_Total'].values[0]:.2f} (GP={hansen_base['GP'].values[0]})"
            )

    return base_df


# Helper to print top N with optional extra player
def print_top_n(df, title, n=5, extra_player=None, extra_label=None):
    if df.empty:
        return

    # Define column map and display columns first
    cn_col_map = {
        "PLAYER_NAME": "çƒå‘˜",
        "PLAYER_POSITION": "ä½ç½®",
        "EDI_Total": "é˜²å®ˆç»Ÿæ²»åŠ›",
        "D1_Score": "å¯¹ä½å‹åˆ¶",
        "D2_Score": "å†…å¤–å°é”",
        "D3_Score": "æ´»åŠ›æŒ‡æ•°",
        "D4_Score": "é˜²å®ˆçƒå•†",
        "D5_Score": "ç¯®æ¿ä¿æŠ¤",
        "Stocks": "æŠ¢æ–­+ç›–å¸½",
        "D4_Ratio": "çƒå•†æ¯”å€¼",
        "DREB_PCT": "é˜²å®ˆç¯®æ¿%",
        "D_FG_PCT": "å¯¹æ‰‹å‘½ä¸­%",
        "PCT_PLUSMINUS": "å¯¹ä½å‹åˆ¶å·®%",
        "PCT_PLUSMINUS_ADJ": "MDè°ƒæ•´å‹åˆ¶å·®%",
        "NORMAL_FG_PCT": "å¯¹æ‰‹é¢„æœŸå‘½ä¸­%",
        "MATCHUP_DIFFICULTY": "å¯¹ä½éš¾åº¦",
        "MD_Percentile": "å¯¹ä½éš¾åº¦%",
        "Rim_DFG": "æŠ¤ç­å‘½ä¸­%",
        "Rim_PLUSMINUS": "æŠ¤ç­å‹åˆ¶å·®%",
        "3PT_DFG": "ä¸‰åˆ†å‘½ä¸­%",
        "3PT_PLUSMINUS": "ä¸‰åˆ†å‹åˆ¶å·®%",
        "DEFLECTIONS": "å¹²æ‰°æ¬¡æ•°",
        "PF": "çŠ¯è§„",
        # æ•ˆç‡æ¨¡å‹ç›¸å…³
        "Efficiency": "é˜²å®ˆæ•ˆç‡ç³»æ•°",
        "Actual_Output": "å®é™…äº§å‡º",
        "Expected_Output": "é¢„æœŸäº§å‡º",
        "Input_Score": "æŠ•å…¥åˆ†",
        "Efficiency_Residual": "æ•ˆç‡æ®‹å·®",
    }

    display_cols = [
        "PLAYER_NAME",
        "PLAYER_POSITION",
        "EDI_Total",
        "D1_Score",
        "D2_Score",
        "D3_Score",
        "D4_Score",
        "D5_Score",
    ]

    total_count = len(df)
    print(f"\nğŸ† {title} Top {n}:")
    sorted_df = df.sort_values("EDI_Total", ascending=False)
    top_df = sorted_df.head(n)

    # If extra_player specified and not in top N, add them
    if extra_player:
        extra_mask = sorted_df["PLAYER_NAME"].str.contains(
            extra_player, case=False, na=False
        )
        if extra_mask.any():
            extra_row = sorted_df[extra_mask].iloc[0:1]
            # Check if already in top N
            if (
                not top_df["PLAYER_NAME"]
                .str.contains(extra_player, case=False, na=False)
                .any()
            ):
                # Calculate rank
                extra_rank = (
                    sorted_df["EDI_Total"] > extra_row["EDI_Total"].values[0]
                ).sum() + 1
                top_df = pd.concat([top_df, extra_row])
                print(f"   (åŒ…å« {extra_player}, æ’å #{extra_rank}/{total_count})")

    # Filter display columns
    current_display_cols = [c for c in display_cols if c in df.columns]
    disp = top_df[current_display_cols].copy()
    disp = disp.rename(columns=cn_col_map)
    print(disp.round(2).to_string(index=False))
    return sorted_df  # Return for visualization


def create_individual_radar_charts(df, save_path, main_title="çƒå‘˜é˜²å®ˆèƒ½åŠ›ç”»åƒ"):
    """
    ä¸ºæ¯ä¸ªçƒå‘˜åˆ›å»ºå•ç‹¬çš„é›·è¾¾å›¾ï¼Œæ¨ªå‘æ’åˆ—
    å‚è€ƒå›¾ç‰‡æ ·å¼ï¼šæ¯ä¸ªçƒå‘˜ä¸€ä¸ªå­å›¾ï¼Œæ˜¾ç¤ºçƒå‘˜åå’Œ EDI åˆ†æ•°
    """
    n_players = len(df)
    if n_players == 0:
        print("   WARNING: No players to plot")
        return

    # Dimension labels in Chinese
    categories = ["å¯¹ä½å‹åˆ¶", "å†…å¤–å°é”", "æ´»åŠ›æŒ‡æ•°", "é˜²å®ˆçƒå•†", "ç¯®æ¿ä¿æŠ¤"]
    N = len(categories)

    # Compute angle for each axis
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1]  # Complete the loop

    # Color palette for each player (different colors)
    colors = ["#FF6B6B", "#4ECDC4", "#45B7D1", "#96CEB4", "#FFEAA7", "#DDA0DD"]

    # Create figure with subplots (1 row, n_players columns)
    fig_width = 4 * n_players
    fig, axes = plt.subplots(
        1, n_players, figsize=(fig_width, 5), subplot_kw=dict(polar=True)
    )

    # Handle single player case
    if n_players == 1:
        axes = [axes]

    # Plot each player in their own subplot
    for idx, (_, row) in enumerate(df.iterrows()):
        ax = axes[idx]
        color = colors[idx % len(colors)]

        values = [
            row["D1_Score"],
            row["D2_Score"],
            row["D3_Score"],
            row["D4_Score"],
            row["D5_Score"],
        ]
        values += values[:1]  # Complete the loop

        # Plot the radar
        ax.plot(angles, values, "o-", linewidth=2, color=color)
        ax.fill(angles, values, alpha=0.25, color=color)

        # Set category labels
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels(categories, size=9, fontweight="bold")

        # Set y-axis limits (0 to 1 for percentile scores)
        ax.set_ylim(0, 1)
        ax.set_yticks([0.5, 1.0])
        ax.set_yticklabels(["50%", "100%"], size=8, color="gray")

        # Add gridlines
        ax.grid(True, linestyle="--", alpha=0.5)

        # Title with player name and EDI score
        ax.set_title(
            f"{row['PLAYER_NAME']}\né˜²å®ˆç»Ÿæ²»åŠ›: {row['EDI_Total']:.1f}",
            size=11,
            fontweight="bold",
            pad=15,
        )

    # Main title
    fig.suptitle(f"{main_title} ({SEASON})", size=16, fontweight="bold", y=1.05)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches="tight", facecolor="white")
    print(f"å·²ä¿å­˜: {save_path}")
    plt.close()


def plot_history_radar(history_df):
    """
    ç»˜åˆ¶åº“é‡ŒèŒä¸šç”Ÿæ¶¯é˜²å®ˆæ¼”å˜é›·è¾¾å›¾ (ä¸­æ–‡ç‰ˆ)
    """
    import matplotlib

    matplotlib.rcParams["font.sans-serif"] = [
        "SimHei",
        "Microsoft YaHei",
        "Arial Unicode MS",
    ]
    matplotlib.rcParams["axes.unicode_minus"] = False

    if history_df.empty:
        return

    # äº”ç»´ä¸­æ–‡æ ‡ç­¾
    categories = [
        "D1: å¯¹ä½å‹åˆ¶",
        "D2: å†…å¤–å°é”",
        "D3: æ´»åŠ›æŒ‡æ•°",
        "D4: é˜²å®ˆçƒå•†",
        "D5: ç¯®æ¿ä¿æŠ¤",
    ]
    N = len(categories)

    # è®¡ç®—è§’åº¦
    angles = [n / float(N) * 2 * np.pi for n in range(N)]
    angles += angles[:1]

    # åˆå§‹åŒ–å›¾è¡¨
    fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(polar=True))

    # ä¸‰ä¸ªé˜¶æ®µçš„æ ·å¼é…ç½®
    styles = {
        "2016-17": {
            "color": "#FFC72C",  # å‹‡å£«é‡‘è‰²
            "linestyle": "--",
            "linewidth": 2.5,
            "label": "2016-17 å·…å³°ç‹æœ",
            "alpha": 0.15,
        },
        "2021-22": {
            "color": "#1D428A",  # å‹‡å£«è“è‰²
            "linestyle": "-.",
            "linewidth": 2.5,
            "label": "2021-22 ç‹è€…å½’æ¥",
            "alpha": 0.15,
        },
        "2024-25": {
            "color": "#006BB6",  # NBAè“
            "linestyle": "-",
            "linewidth": 3,
            "label": "2024-25 è€å°†èµ›å­£",
            "alpha": 0.2,
        },
    }

    # ç»˜åˆ¶æ¯ä¸ªèµ›å­£
    for _, row in history_df.iterrows():
        season = row["SEASON_ID"]
        style = styles.get(
            season,
            {
                "color": "gray",
                "linestyle": "-",
                "linewidth": 1,
                "label": season,
                "alpha": 0.1,
            },
        )

        values = [
            row.get("D1_Score", 0.5),
            row.get("D2_Score", 0.5),
            row.get("D3_Score", 0.5),
            row.get("D4_Score", 0.5),
            row.get("D5_Score", 0.5),
        ]
        values = [0.5 if pd.isna(v) else v for v in values]
        values += values[:1]

        ax.plot(
            angles,
            values,
            color=style["color"],
            linestyle=style["linestyle"],
            linewidth=style["linewidth"],
            label=style["label"],
            marker="o",
            markersize=6,
        )
        ax.fill(angles, values, color=style["color"], alpha=style["alpha"])

    # è®¾ç½®æ ‡ç­¾
    ax.set_xticks(angles[:-1])
    ax.set_xticklabels(categories, size=12, fontweight="bold")

    # è®¾ç½®Yè½´
    ax.set_ylim(0, 1)
    ax.set_yticks([0.25, 0.5, 0.75, 1.0])
    ax.set_yticklabels(["25%", "50%", "75%", "100%"], size=9, color="gray")

    # æ ‡é¢˜å’Œå›¾ä¾‹
    plt.title(
        "æ–¯è’‚èŠ¬Â·åº“é‡Œï¼šé˜²å®ˆèƒ½åŠ›æ¼”å˜\n(å·…å³°ç‹æœ vs ç‹è€…å½’æ¥ vs è€å°†èµ›å­£)",
        size=16,
        fontweight="bold",
        y=1.1,
    )
    plt.legend(loc="upper right", bbox_to_anchor=(1.35, 1.1), fontsize=11)

    # ä¿å­˜
    save_path = FIGURES_DIR / "nba_defense_curry_history.png"
    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches="tight", facecolor="white")
    print(f"å·²ä¿å­˜: {save_path}")
    plt.close()


if __name__ == "__main__":
    if HISTORY_MODE:
        print(f"=== NBA Defense MVP Analysis (History Mode: Curry Eras) ===")
        target_seasons = ["2016-17", "2021-22", "2024-25"]
        curry_id = 201939
        history_results = []

        for s in target_seasons:
            try:
                # Use a larger timeout or retry logic handled inside analyze_season/get_league_data
                season_df = analyze_season(s)

                if not season_df.empty:
                    # Find Curry
                    curry_data = season_df[season_df["PLAYER_ID"] == curry_id]
                    if not curry_data.empty:
                        row = curry_data.iloc[0].to_dict()
                        row["SEASON_ID"] = s
                        history_results.append(row)
                        print(
                            f"   -> Found Curry in {s}: EDI={row.get('EDI_Total', 0):.1f}"
                        )
                    else:
                        print(f"   -> WARNING: Stephen Curry not found in {s}")
                        # Append empty/default row to keep structure? Or just skip?
                        # Let's append a row with 0s/NaNs so we know we tried
                        empty_row = {col: np.nan for col in season_df.columns}
                        empty_row["PLAYER_NAME"] = "Stephen Curry"
                        empty_row["PLAYER_ID"] = curry_id
                        empty_row["SEASON_ID"] = s
                        history_results.append(empty_row)
            except Exception as e:
                print(f"   ERROR analyzing {s}: {e}")

        # Summary Table
        if history_results:
            history_df = pd.DataFrame(history_results)

            # Reorder columns for readability
            cols_order = [
                "SEASON_ID",
                "PLAYER_NAME",
                "EDI_Total",
                "D1_Score",
                "D2_Score",
                "D3_Score",
                "D4_Score",
                "D5_Score",
                "Efficiency",
                "Actual_Output",
                "Expected_Output",
            ]
            # Filter to exist cols
            cols_order = [c for c in cols_order if c in history_df.columns]

            print("\n" + "=" * 60)
            print("ğŸ€ Stephen Curry: Career Defense Evolution (3 Eras)")
            print("=" * 60)
            print(history_df[cols_order].round(2).to_string(index=False))

            # Save
            history_df.to_csv(DATA_DIR / "nba_defense_curry_history.csv", index=False)
            print(
                f"\nğŸ“ History saved to: {DATA_DIR / 'nba_defense_curry_history.csv'}"
            )

            # Plot
            plot_history_radar(history_df)

    else:
        print(f"=== NBA Defense MVP Analysis ({SEASON}) ===")
        print(f"Target Players: {TARGET_PLAYERS}\n")

        # Call the encapsulated function
        base_df = analyze_season(SEASON)

        # =============================================================================
        # STEP 3: FILTER TARGET PLAYERS & RANKING
        # =============================================================================
        if not base_df.empty:
            # Filter for specific target players for the radar chart
            final_results = []
            for target in TARGET_PLAYERS:
                match_mask = (
                    base_df["PLAYER_NAME"].astype(str).str.contains(target, case=False)
                )
                match = base_df[match_mask]
                if not match.empty:
                    final_results.append(match.iloc[0])
                else:
                    print(f"   WARNING: Could not find data for {target}")

            results_df = pd.DataFrame(final_results)

            # =============================================================================
            # STEP 4: OUTPUT RESULTS
            # =============================================================================

            print("\n" + "=" * 80)
            print("                    ğŸ€ NBA é˜²å®ˆç»Ÿæ²»åŠ›æ’è¡Œæ¦œ ğŸ€")
            print("=" * 80)
            print(
                "\nğŸ“Š ã€æ¨¡å‹æ–¹æ³•è®ºã€‘è´å¶æ–¯äº”ç»´é˜²å®ˆè¯„ä¼°æ¡†æ¶ (Bayesian 5-Dimension Defensive Evaluation)"
            )
            print(
                "   æ ¸å¿ƒæ€æƒ³: å°†é˜²å®ˆæ‹†è§£ä¸º5ä¸ªç‹¬ç«‹ç»´åº¦ï¼Œæ¯ä¸ªç»´åº¦ä½¿ç”¨ç™¾åˆ†ä½æ’å(0-100%)ä½œä¸ºå…ˆéªŒæ¦‚ç‡ï¼Œ"
            )
            print(
                '             é€šè¿‡è´å¶æ–¯æ”¶ç¼©è°ƒæ•´åï¼Œä½¿ç”¨æ•ˆç‡æ¨¡å‹æ¡†æ¶åŠ æƒå¹³å‡å¾—å‡º"é˜²å®ˆç»Ÿæ²»åŠ›"æŒ‡æ•°ã€‚'
            )
            print("\nğŸ“Š è´å¶æ–¯é€»è¾‘:")
            print("   â€¢ å…ˆéªŒåˆ†å¸ƒ: æ¯ä¸ªç»´åº¦çš„è”ç›Ÿåˆ†å¸ƒä½œä¸ºå…ˆéªŒ (Prior)")
            print("   â€¢ ä¼¼ç„¶å‡½æ•°: çƒå‘˜å®é™…è¡¨ç°æ•°æ®ä½œä¸ºä¼¼ç„¶ (Likelihood)")
            print("   â€¢ åéªŒä¼°è®¡: D_k = (n Ã— raw_pct + C Ã— 0.5) / (n + C)")
            print(f"   â€¢ æ”¶ç¼©å¸¸æ•°: C = {BAYES_C} (æ ·æœ¬é‡è¾¾åˆ° C æ—¶ï¼Œæ•°æ®æƒé‡ = 50%)")
            print("\nğŸ“Š æ•ˆç‡æ¨¡å‹æ¡†æ¶ (Efficiency Model Framework):")
            print(
                "   â€¢ æŠ•å…¥å±‚ (Input): D3 (æ´»åŠ›æŒ‡æ•°) + D4 (é˜²å®ˆçƒå•†) - å½±å“é˜²å®ˆç»“æœçš„åŠªåŠ›/æ–¹å¼"
            )
            print(
                "   â€¢ äº§å‡ºå±‚ (Output): D1 (å¯¹ä½å‹åˆ¶) + D2 (å†…å¤–å°é”) - é˜²å®ˆçš„ç›´æ¥ç»“æœ"
            )
            print("   â€¢ ç‹¬ç«‹å±‚: D5 (ç¯®æ¿ä¿æŠ¤) - ä¸å‚ä¸æ•ˆç‡è®¡ç®—")
            print("   â€¢ å›å½’æ¨¡å‹: Expected_Output = Î± + Î² Ã— Input_Score")
            print(
                "   â€¢ æ•ˆç‡ç³»æ•°: Efficiency = Actual_Output / Expected_Output (é™åˆ¶åœ¨ 0.5-1.5)"
            )
            print(
                "   â€¢ EDIå…¬å¼: EDI = [OutputÃ—EfficiencyÃ—(W1+W2) + InputÃ—(W3+W4) + D5Ã—W5] / æ€»æƒé‡"
            )
            print("   â€¢ é«˜æ•ˆçƒå‘˜: æŠ•å…¥å°‘ä½†äº§å‡ºé«˜ (å¤©èµ‹/é˜²å®ˆæ™ºæ…§) â†’ Efficiency > 1.0")
            print("   â€¢ ä½æ•ˆçƒå‘˜: æŠ•å…¥å¤šä½†äº§å‡ºä½ (ç©ºæœ‰åŠªåŠ›) â†’ Efficiency < 1.0")
            print("\nğŸ“Š è§’è‰²ç›¸å…³æ€§ç³»æ•° (Role Relevance Coefficient):")
            print("   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”")
            print("   â”‚ è§’è‰²        â”‚ D2 å†…å¤–å°é”æƒé‡           â”‚ D5 ç¯®æ¿æƒé‡ç³»æ•° â”‚")
            print("   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤")
            print("   â”‚ Guards (G)  â”‚ å¤–çº¿60% / å†…çº¿40%         â”‚ 0.5 (è¡°å‡50%)   â”‚")
            print("   â”‚ Frontcourt  â”‚ å¤–çº¿40% / å†…çº¿60%         â”‚ 1.0 (å®Œæ•´ä¿ç•™)  â”‚")
            print("   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜")
            print("\nğŸ“Š äº”ç»´è¯´æ˜ (Value Added + Matchup Difficulty æ”¹è¿›ç‰ˆ):")
            print(
                "   | D1 å¯¹ä½å‹åˆ¶: PCT_PLUSMINUS Ã— (1 + 0.3 Ã— MD_Zscore) | MDè°ƒæ•´ï¼šé˜²å®ˆå¼ºäººåŠ åˆ†ï¼Œèº²é¿é˜²å®ˆå‡åˆ† |"
            )
            print(
                "   | D2 å†…å¤–å°é”: PLUSMINUS (æŠ¤ç­+ä¸‰åˆ†ï¼ŒæŒ‰è§’è‰²åŠ æƒ) | åŒæ ·ä½¿ç”¨ Value Added æ–¹æ³• |"
            )
            print(
                "   | D3 æ´»åŠ›æŒ‡æ•°: å¹²æ‰°çƒ + é€ è¿›æ”»çŠ¯è§„Ã—2 + å¹²æ‰°æŠ•ç¯® (Z-Score) | æ•°æ®æº: LeagueHustleStatsPlayer |"
            )
            print(
                '   | D4 é˜²å®ˆçƒå•†: (æŠ¢æ–­ + ç›–å¸½) / (çŠ¯è§„ + 1) | æ•ˆç‡å‹æŒ‡æ ‡ï¼Œæƒ©ç½š"ç«™æ¡©å‹"ä½çŠ¯è§„çƒå‘˜ |'
            )
            print(
                "   | D5 ç¯®æ¿ä¿æŠ¤: é˜²å®ˆç¯®æ¿ç‡ (DREB%) | æ•°æ®æº: LeagueDashPlayerStats (Advanced) |"
            )
            print("\nğŸ“Š Matchup Difficulty (MD) å¯¹ä½éš¾åº¦è°ƒæ•´:")
            print("   â€¢ æ•°æ®æº: LeagueSeasonMatchups (æ¯å¯¹æ”»é˜²çƒå‘˜çš„å›åˆæ•°æ®)")
            print(
                "   â€¢ è®¡ç®—æ–¹æ³•: æ¯ä½è¿›æ”»çƒå‘˜çš„ PTS/100å›åˆ â†’ æ¯ä½é˜²å®ˆè€…çš„å¯¹ä½éš¾åº¦åŠ æƒå¹³å‡"
            )
            print("   â€¢ MD_Zscore > 0: é˜²å®ˆå¼ºå¾—åˆ†æ‰‹ (å¦‚Dillon Brooksé˜²å®ˆCurry)")
            print("   â€¢ MD_Zscore < 0: èº²é¿å¼ºå¾—åˆ†æ‰‹ (å¦‚Curryé˜²å®ˆå¼±ä¾§ç¿¼)")
            print("   â€¢ D1è°ƒæ•´: Adjusted_VA = PCT_PLUSMINUS Ã— (1 + 0.3 Ã— MD_Zscore)")
            print(
                "   â€¢ ç¤ºä¾‹: -5%å‹åˆ¶å·® + MD_Zscore=1 â†’ -6.5% (å¥–åŠ±); MD_Zscore=-2 â†’ -2% (æƒ©ç½š)"
            )
            print("\nğŸ“Š Value Added æ”¹è¿›è¯´æ˜:")
            print("   â€¢ è§£å†³é—®é¢˜: é˜²å®ˆä½æ•ˆæŠ•æ‰‹(å¦‚åº•è§’å°„æ‰‹)è·å¾—é«˜åˆ†çš„é—®é¢˜")
            print("   â€¢ æ”¹è¿›æ–¹æ³•: ä½¿ç”¨ PCT_PLUSMINUS = D_FG_PCT - NORMAL_FG_PCT")
            print("   â€¢ è§£è¯»: è®©å¯¹æ‰‹æ¯”ä»–é¢„æœŸå‘½ä¸­ç‡ä½å¤šå°‘ï¼Œè€ŒéåŸå§‹å‘½ä¸­ç‡")
            print(
                "   â€¢ ç¤ºä¾‹: è®©50%å‘½ä¸­ç‡çƒå‘˜é™åˆ°45% (VA=-5%) > è®©40%çƒå‘˜ç»´æŒ40% (VA=0%)"
            )
            print("-" * 80)

            # League Top 5
            league_sorted = print_top_n(base_df, "è”ç›Ÿ (League)", n=5)

            # Positional Rankings
            guards = base_df[
                base_df["PLAYER_POSITION"].str.contains("G", na=False)
                & ~base_df["PLAYER_POSITION"].str.contains("F", na=False)
            ]  # çº¯åå«
            frontcourt = base_df[base_df["ROLE"] == "Frontcourt"]  # å‰åœº (å«Fæˆ–C)

            # åå« Top 5 + Curry
            guards_sorted = print_top_n(
                guards,
                "åå« (Guards)",
                n=5,
                extra_player="Stephen Curry",
                extra_label="Curry",
            )
            # å‰åœº Top 5 + Hansen Yang (ä»… 2025-26 èµ›å­£)
            if SEASON == "2025-26":
                print_top_n(
                    frontcourt,
                    "å‰åœº (Frontcourt)",
                    n=5,
                    extra_player="Hansen",
                    extra_label="Hansen Yang",
                )
            else:
                print_top_n(frontcourt, "å‰åœº (Frontcourt)", n=5)

            # Save all data to CSV
            base_df.to_csv(
                DATA_DIR / f"nba_defensive_all_players_{SEASON}.csv", index=False
            )
            print(
                f"\nğŸ“ å·²ä¿å­˜: {DATA_DIR / f'nba_defensive_all_players_{SEASON}.csv'} (å…¨éƒ¨çƒå‘˜)"
            )

            if not results_df.empty:
                results_df = results_df.sort_values("EDI_Total", ascending=False)
                results_df.to_csv(
                    DATA_DIR / f"nba_defensive_mvp_results_{SEASON}.csv", index=False
                )
                print(
                    f"ğŸ“ å·²ä¿å­˜: {DATA_DIR / f'nba_defensive_mvp_results_{SEASON}.csv'} (ç›®æ ‡çƒå‘˜)"
                )

            # =============================================================================
            # STEP 5: RADAR CHART VISUALIZATION (æ¯ä¸ªçƒå‘˜å•ç‹¬ä¸€ä¸ªé›·è¾¾å›¾)
            # =============================================================================
            print("\nç”Ÿæˆé›·è¾¾å›¾...")

            # Configure matplotlib for Chinese font support
            plt.rcParams["font.sans-serif"] = [
                "Microsoft YaHei",
                "SimHei",
                "DejaVu Sans",
            ]
            plt.rcParams["axes.unicode_minus"] = False

            # è”ç›Ÿ Top 5 å•ç‹¬é›·è¾¾å›¾
            league_top5 = base_df.sort_values("EDI_Total", ascending=False).head(5)
            create_individual_radar_charts(
                league_top5,
                FIGURES_DIR / f"nba_defense_league_top5_{SEASON}.png",
                "è”ç›Ÿ Top 5 é˜²å®ˆèƒ½åŠ›ç”»åƒ",
            )

            # åå« Top 5 + Curry å•ç‹¬é›·è¾¾å›¾
            guards_sorted = guards.sort_values("EDI_Total", ascending=False)
            guard_top5 = guards_sorted.head(5)
            guards_total = len(guards_sorted)

            # æ·»åŠ  Curry (å¦‚æœä¸åœ¨ Top 5 ä¸­)
            curry_mask = guards_sorted["PLAYER_NAME"].str.contains(
                "Stephen Curry", case=False, na=False
            )
            if curry_mask.any():
                curry_row = guards_sorted[curry_mask].iloc[0:1]
                if (
                    not guard_top5["PLAYER_NAME"]
                    .str.contains("Stephen Curry", case=False, na=False)
                    .any()
                ):
                    curry_rank = (
                        guards_sorted["EDI_Total"] > curry_row["EDI_Total"].values[0]
                    ).sum() + 1
                    guard_top5 = pd.concat([guard_top5, curry_row])
                    curry_note = f" (å«Curry #{curry_rank}/{guards_total})"
                else:
                    curry_note = ""
            else:
                curry_note = " (Curryæœªæ‰¾åˆ°)"

            create_individual_radar_charts(
                guard_top5,
                FIGURES_DIR / f"nba_defense_guard_top5_{SEASON}.png",
                f"åå« Top 5 é˜²å®ˆèƒ½åŠ›ç”»åƒ{curry_note}",
            )

            # å‰åœº Top 5 å•ç‹¬é›·è¾¾å›¾ (2025-26 èµ›å­£åŒ…å« Hansen Yang)
            # ä½¿ç”¨ Frontcourt (ROLE == "Frontcourt"ï¼ŒåŒ…å«Få’ŒC)
            frontcourt_sorted = base_df[base_df["ROLE"] == "Frontcourt"].sort_values(
                "EDI_Total", ascending=False
            )
            frontcourt_top5 = frontcourt_sorted.head(5)
            frontcourt_total = len(frontcourt_sorted)

            # 2025-26 èµ›å­£æ·»åŠ  Hansen Yang (å¦‚æœä¸åœ¨ Top 5 ä¸­)
            hansen_note = ""
            if SEASON == "2025-26":
                hansen_mask = frontcourt_sorted["PLAYER_NAME"].str.contains(
                    "Hansen", case=False, na=False
                )
                if hansen_mask.any():
                    hansen_row = frontcourt_sorted[hansen_mask].iloc[0:1]
                    if (
                        not frontcourt_top5["PLAYER_NAME"]
                        .str.contains("Hansen", case=False, na=False)
                        .any()
                    ):
                        hansen_rank = (
                            frontcourt_sorted["EDI_Total"]
                            > hansen_row["EDI_Total"].values[0]
                        ).sum() + 1
                        frontcourt_top5 = pd.concat([frontcourt_top5, hansen_row])
                        hansen_note = f" (å«Hansen #{hansen_rank}/{frontcourt_total})"
                else:
                    hansen_note = " (Hansenæœªæ‰¾åˆ°)"

            create_individual_radar_charts(
                frontcourt_top5,
                FIGURES_DIR / f"nba_defense_frontcourt_top5_{SEASON}.png",
                f"å‰åœº Top 5 é˜²å®ˆèƒ½åŠ›ç”»åƒ{hansen_note}",
            )

            print("\n[å®Œæˆ] åˆ†æç»“æŸ!")
